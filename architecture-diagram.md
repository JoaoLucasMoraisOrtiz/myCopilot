# Arquitetura do Agente de Reengenharia Java Legacy

## â— PARADIGMA FUNDAMENTAL: REENGENHARIA EM VEZ DE MIGRAÃ‡ÃƒO

**Problema identificado**: Sistemas legados sÃ£o frequentemente inviÃ¡veis para migraÃ§Ã£o direta devido a:
- God Classes e arquitetura monolÃ­tica
- CÃ³digo espaguete e baixa coesÃ£o
- DependÃªncias circulares e acoplamento forte
- Falta de testes e documentaÃ§Ã£o

**SoluÃ§Ã£o**: **Reengenharia Completa** - Entender profundamente o sistema legacy e reconstruir do zero seguindo as especificaÃ§Ãµes do `Instr.md`.

## Diagrama Principal do Sistema de Reengenharia

```mermaid
graph TD
    A[ğŸ“„ Instr.md - EspecificaÃ§Ãµes do Novo Sistema] --> B[ï¿½ï¸ Deep System Analysis]
    B --> C[ğŸ§  Knowledge Extraction Engine]
    C --> D[ï¿½ Business Logic Mapper]
    D --> E[ï¿½ï¸ Feature Backlog Generator]
    
    E --> F[ğŸ¯ Task Prioritizer]
    F --> G[ğŸ—ï¸ Architecture Designer]
    G --> H[ï¿½ Iterative Construction Pipeline]
    
    H --> I[ğŸ“ Context Selector RAG]
    I --> J[ğŸ¤– Amazon Q CLI Interface]
    J --> K[ğŸ“ JSON Response Parser]
    K --> L[ğŸ­ New Code Generator]
    
    L --> M[ğŸ§ª Automated Testing]
    M --> N{âœ”ï¸ Feature Complete?}
    N -->|NÃ£o| O[ğŸ”„ Feature Refinement]
    O --> I
    N -->|Sim| P[âœ… Feature Integration]
    P --> Q[ğŸ“Š Progress Tracking]
    Q --> R{ğŸ¯ All Features Done?}
    R -->|NÃ£o| F
    R -->|Sim| S[ğŸ‰ System Complete]
    
    T[ğŸ’¼ Legacy Analyzer] --> C
    T --> D
    U[ğŸ—ƒï¸ Knowledge Base] --> I
    
    style A fill:#e1f5fe
    style C fill:#fff3e0
    style L fill:#e8f5e8
    style N fill:#fff9c4
    style S fill:#c8e6c9
```

## Diagrama de Fases da Reengenharia

```mermaid
flowchart TD
    subgraph "Fase 1: AnÃ¡lise Profunda"
        A1[Sistema Legacy]
        A2[Code Analysis]
        A3[Business Logic Extraction]
        A4[API Discovery]
        A5[Data Flow Mapping]
    end
    
    subgraph "Fase 2: Modelagem"
        B1[Domain Modeling]
        B2[Feature Decomposition]
        B3[Architecture Design]
        B4[Backlog Creation]
    end
    
    subgraph "Fase 3: ConstruÃ§Ã£o Iterativa"
        C1[Feature Selection]
        C2[Context Assembly]
        C3[Amazon Q Generation]
        C4[Code Integration]
        C5[Testing & Validation]
    end
    
    subgraph "Fase 4: Sistema Novo"
        D1[Clean Architecture]
        D2[Modern Stack]
        D3[Comprehensive Tests]
        D4[Documentation]
    end
    
    A1 --> A2
    A2 --> A3
    A3 --> A4
    A4 --> A5
    A5 --> B1
    B1 --> B2
    B2 --> B3
    B3 --> B4
    B4 --> C1
    C1 --> C2
    C2 --> C3
    C3 --> C4
    C4 --> C5
    C5 --> C1
    C5 --> D1
    D1 --> D2
    D2 --> D3
    D3 --> D4
```

## Estrutura de Componentes Reformulada

```mermaid
classDiagram
    class LegacySystemAnalyzer {
        +deepScan()
        +extractBusinessLogic()
        +mapDataFlow()
        +identifyAPIs()
        +analyzeComplexity()
        +generateInsights()
    }
    
    class KnowledgeExtractor {
        +parseCodeStructure()
        +extractDomainConcepts()
        +mapBusinessRules()
        +identifyPatterns()
        +buildKnowledgeGraph()
    }
    
    class FeatureDecomposer {
        +identifyFeatures()
        +prioritizeFeatures()
        +createBacklog()
        +estimateComplexity()
        +defineAcceptanceCriteria()
    }
    
    class ArchitecturalDesigner {
        +designCleanArchitecture()
        +defineBoundedContexts()
        +selectPatterns()
        +createBlueprint()
    }
    
    class ContextAssembler {
        +selectRelevantLegacyCode()
        +buildFeatureContext()
        +assembleKnowledge()
        +optimizeForAI()
    }
    
    class NewSystemGenerator {
        +generateFromScratch()
        +implementFeature()
        +applyArchitecture()
        +followStandards()
        +createTests()
    }
    
    class QualityValidator {
        +validateBusinessLogic()
        +runFunctionalTests()
        +checkArchitecture()
        +verifyCompliance()
    }
    
    class ProgressOrchestrator {
        +manageBacklog()
        +trackProgress()
        +coordinateFeatures()
        +handleDependencies()
        +generateReports()
    }
    
    LegacySystemAnalyzer --> KnowledgeExtractor
    KnowledgeExtractor --> FeatureDecomposer
    FeatureDecomposer --> ArchitecturalDesigner
    ArchitecturalDesigner --> ContextAssembler
    ContextAssembler --> NewSystemGenerator
    NewSystemGenerator --> QualityValidator
    QualityValidator --> ProgressOrchestrator
    ProgressOrchestrator --> FeatureDecomposer
```

## Fluxo de Estados da Reengenharia

```mermaid
stateDiagram-v2
    [*] --> DeepAnalysis: Iniciar AnÃ¡lise Profunda
    DeepAnalysis --> CodeScanning: Escanear Todo o Sistema
    CodeScanning --> LogicExtraction: Extrair LÃ³gica de NegÃ³cio
    LogicExtraction --> APIDiscovery: Descobrir APIs e Contratos
    APIDiscovery --> DataFlowMapping: Mapear Fluxo de Dados
    
    DataFlowMapping --> DomainModeling: Modelar DomÃ­nio
    DomainModeling --> FeatureDecomposition: Decompor em Features
    FeatureDecomposition --> BacklogCreation: Criar Backlog Priorizado
    BacklogCreation --> ArchitectureDesign: Projetar Nova Arquitetura
    
    ArchitectureDesign --> FeatureSelection: Selecionar PrÃ³xima Feature
    FeatureSelection --> ContextAssembly: Montar Contexto da Feature
    ContextAssembly --> LegacyKnowledgeRetrieval: Recuperar Conhecimento Legacy
    LegacyKnowledgeRetrieval --> AIGeneration: Gerar CÃ³digo Novo
    
    AIGeneration --> CodeIntegration: Integrar ao Sistema Novo
    CodeIntegration --> BusinessValidation: Validar LÃ³gica de NegÃ³cio
    BusinessValidation --> FunctionalTesting: Testes Funcionais
    FunctionalTesting --> FeatureComplete: Feature Completa?
    
    FeatureComplete --> FeatureRefinement: [NÃ£o] Refinar Feature
    FeatureRefinement --> ContextAssembly
    FeatureComplete --> BacklogUpdate: [Sim] Atualizar Backlog
    BacklogUpdate --> SystemComplete: Todas Features ConcluÃ­das?
    
    SystemComplete --> FeatureSelection: [NÃ£o] PrÃ³xima Feature
    SystemComplete --> SystemIntegration: [Sim] IntegraÃ§Ã£o Final
    SystemIntegration --> PerformanceTesting: Testes de Performance
    PerformanceTesting --> Documentation: DocumentaÃ§Ã£o
    Documentation --> [*]
    
    note right of AIGeneration
        Amazon Q CLI com contexto
        especÃ­fico da feature e
        conhecimento do sistema legacy
    end note
    
    note right of BacklogCreation
        Features priorizadas por:
        - Complexidade
        - DependÃªncias
        - Valor de negÃ³cio
    end note
```

## Estrutura de Arquivos para Reengenharia

```mermaid
graph TD
    A[ğŸ“ java-reengineering-agent/] --> B[ğŸ“„ Instr.md]
    A --> C[ğŸ“ src/]
    A --> D[ğŸ“ templates/]
    A --> E[ğŸ“ workspace/]
    A --> F[ğŸ“ output/]
    A --> G[ğŸ“ logs/]
    A --> H[ğŸ“ knowledge_base/]
    
    C --> C1[ğŸ“ analyzers/]
    C --> C2[ğŸ“ extractors/]
    C --> C3[ğŸ“ decomposers/]
    C --> C4[ğŸ“ designers/]
    C --> C5[ğŸ“ generators/]
    C --> C6[ğŸ“ validators/]
    C --> C7[ğŸ“ orchestrators/]
    C --> C8[ğŸ“ rag/]
    C --> C9[ğŸ“ utils/]
    
    C1 --> C1A[legacy_system_analyzer.py]
    C1 --> C1B[code_scanner.py]
    C1 --> C1C[complexity_analyzer.py]
    
    C2 --> C2A[business_logic_extractor.py]
    C2 --> C2B[api_discovery.py]
    C2 --> C2C[data_flow_mapper.py]
    C2 --> C2D[knowledge_extractor.py]
    
    C3 --> C3A[feature_decomposer.py]
    C3 --> C3B[backlog_generator.py]
    C3 --> C3C[dependency_analyzer.py]
    
    C4 --> C4A[architecture_designer.py]
    C4 --> C4B[pattern_selector.py]
    C4 --> C4C[blueprint_creator.py]
    
    C5 --> C5A[new_system_generator.py]
    C5 --> C5B[amazon_q_interface.py]
    C5 --> C5C[code_synthesizer.py]
    
    C6 --> C6A[business_validator.py]
    C6 --> C6B[functional_tester.py]
    C6 --> C6C[quality_checker.py]
    
    C7 --> C7A[progress_orchestrator.py]
    C7 --> C7B[feature_coordinator.py]
    C7 --> C7C[pipeline_manager.py]
    
    D --> D1[ğŸ“ java/]
    D --> D2[ğŸ“ spring-boot/]
    D --> D3[ğŸ“ maven/]
    D --> D4[ğŸ“ prompts/]
    
    D4 --> D4A[ğŸ“ analysis/]
    D4 --> D4B[ğŸ“ decomposition/]
    D4 --> D4C[ğŸ“ generation/]
    D4 --> D4D[ğŸ“ validation/]
    D4 --> D4E[ğŸ“ common/]
    
    D4A --> D4A1[system_analysis.md]
    D4A --> D4A2[business_logic_extraction.md]
    D4A --> D4A3[api_discovery.md]
    D4A --> D4A4[data_flow_mapping.md]
    
    D4B --> D4B1[feature_decomposition.md]
    D4B --> D4B2[backlog_creation.md]
    D4B --> D4B3[dependency_analysis.md]
    D4B --> D4B4[bounded_context_identification.md]
    
    D4C --> D4C1[code_generation.md]
    D4C --> D4C2[test_generation.md]
    D4C --> D4C3[architecture_implementation.md]
    D4C --> D4C4[feature_implementation.md]
    
    D4D --> D4D1[business_validation.md]
    D4D --> D4D2[functional_testing.md]
    D4D --> D4D3[quality_assessment.md]
    D4D --> D4D4[api_compatibility.md]
    
    D4E --> D4E1[base_prompt.md]
    D4E --> D4E2[response_format.md]
    D4E --> D4E3[context_template.md]
    D4E --> D4E4[instruction_guidelines.md]
    
    E --> E1[ğŸ“ legacy-system/]
    E --> E2[ğŸ“ new-system/]
    E --> E3[ğŸ“ analysis-results/]
    E --> E4[ğŸ“ feature-backlog/]
    
    H --> H1[ğŸ“„ legacy_knowledge.db]
    H --> H2[ğŸ“„ business_rules.json]
    H --> H3[ğŸ“„ api_contracts.json]
    H --> H4[ğŸ“„ domain_model.json]
    H --> H5[ğŸ“„ feature_backlog.json]
    
    style C2 fill:#e1f5fe
    style C3 fill:#fff3e0
    style C5 fill:#e8f5e8
    style H fill:#f3e5f5
    style D4 fill:#fff9c4
```

### 7. **Estrutura de Prompts Organizados**

#### **OrganizaÃ§Ã£o dos Prompts por Categoria:**

```yaml
# Estrutura de Templates de Prompts
templates/prompts/
â”œâ”€â”€ analysis/           # Prompts para anÃ¡lise do sistema legacy
â”œâ”€â”€ decomposition/      # Prompts para decomposiÃ§Ã£o em features
â”œâ”€â”€ generation/         # Prompts para geraÃ§Ã£o de cÃ³digo novo
â”œâ”€â”€ validation/         # Prompts para validaÃ§Ã£o e testes
â””â”€â”€ common/            # Prompts base e templates reutilizÃ¡veis
```

#### **ğŸ“ analysis/ - Prompts de AnÃ¡lise**

```markdown
# system_analysis.md
ROLE: Senior Software Architect specializing in legacy system analysis

TASK: Analyze the provided legacy Java system and extract comprehensive insights

INPUT_CONTEXT:
- Legacy system source code
- Configuration files
- Documentation (if available)
- Deployment scripts

OUTPUT_FORMAT: {
    "system_overview": {
        "language_version": "string",
        "frameworks": ["list"],
        "architecture_pattern": "string",
        "complexity_score": "number (1-10)"
    },
    "code_structure": {
        "total_classes": "number",
        "god_classes": ["list of classes with >500 LOC"],
        "circular_dependencies": ["list"],
        "design_patterns": ["detected patterns"]
    },
    "technical_debt": {
        "anti_patterns": ["list"],
        "code_smells": ["list"],
        "security_issues": ["list"]
    },
    "recommendations": ["prioritized list of issues to address"]
}

ANALYSIS_GUIDELINES:
1. Focus on business logic extraction
2. Identify clear architectural boundaries
3. Map data flow between components
4. Assess testability and maintainability
```

#### **ğŸ“ decomposition/ - Prompts de DecomposiÃ§Ã£o**

```markdown
# feature_decomposition.md
ROLE: Domain-Driven Design Expert

TASK: Decompose the analyzed legacy system into independent, cohesive features

INPUT_CONTEXT:
- System analysis results
- Business domain knowledge
- User stories or requirements
- API contracts

OUTPUT_FORMAT: {
    "bounded_contexts": [
        {
            "name": "string",
            "description": "string",
            "entities": ["list"],
            "value_objects": ["list"],
            "aggregates": ["list"]
        }
    ],
    "features": [
        {
            "id": "string",
            "name": "string",
            "description": "string",
            "bounded_context": "string",
            "complexity": "low|medium|high",
            "business_value": "low|medium|high",
            "dependencies": ["list of feature IDs"],
            "acceptance_criteria": ["list"],
            "estimated_effort": "string"
        }
    ]
}

DECOMPOSITION_PRINCIPLES:
1. High cohesion within features
2. Low coupling between features
3. Clear business value
4. Independent deployability
5. Testable in isolation
```

#### **ğŸ“ generation/ - Prompts de GeraÃ§Ã£o**

```markdown
# code_generation.md
ROLE: Senior Java Developer with expertise in Spring Boot and Clean Architecture

TASK: Generate modern, clean Java code implementing the specified feature

INPUT_CONTEXT:
- Feature specification
- Legacy implementation reference
- Business rules to preserve
- Architecture constraints
- API contracts to maintain

TARGET_ARCHITECTURE:
- Java 17
- Spring Boot 3.2.0
- Clean Architecture (Hexagonal)
- Domain-Driven Design
- Test-Driven Development

OUTPUT_FORMAT: {
    "files": [
        {
            "path": "relative/path/to/file.java",
            "content": "complete file content",
            "purpose": "description",
            "layer": "domain|application|infrastructure|presentation"
        }
    ],
    "tests": [
        {
            "path": "relative/path/to/test.java",
            "content": "complete test content",
            "type": "unit|integration|acceptance"
        }
    ],
    "configuration": {
        "dependencies": ["list of new Maven dependencies"],
        "properties": {"key": "value pairs for application.yml"}
    },
    "documentation": {
        "readme": "feature documentation",
        "api_docs": "endpoint documentation if applicable"
    }
}

QUALITY_REQUIREMENTS:
- Test coverage > 90%
- Cyclomatic complexity < 10
- No code duplication
- SOLID principles
- Dependency injection
- Exception handling
- Input validation
- Logging and monitoring
```

#### **ğŸ“ validation/ - Prompts de ValidaÃ§Ã£o**

```markdown
# business_validation.md
ROLE: Business Analyst and QA Engineer

TASK: Validate that the reengineered feature preserves all business logic

INPUT_CONTEXT:
- Original legacy feature behavior
- New implementation
- Business rules documentation
- Test scenarios

OUTPUT_FORMAT: {
    "validation_results": {
        "business_logic_preserved": "boolean",
        "api_compatibility": "boolean",
        "data_integrity": "boolean",
        "performance_acceptable": "boolean"
    },
    "test_scenarios": [
        {
            "scenario": "description",
            "input": "test data",
            "expected_output": "expected result",
            "actual_output": "actual result",
            "status": "pass|fail",
            "notes": "observations"
        }
    ],
    "discrepancies": [
        {
            "type": "business_logic|api|data|performance",
            "description": "what differs",
            "impact": "low|medium|high",
            "recommendation": "how to fix"
        }
    ]
}

VALIDATION_CRITERIA:
1. All business rules must be preserved
2. API contracts must be maintained
3. Data transformations must be equivalent
4. Performance must be equal or better
5. Error handling must be consistent
```

#### **ğŸ“ common/ - Templates Base**

```markdown
# base_prompt.md
SYSTEM_ROLE: Expert Java Software Engineer with 15+ years experience in legacy system modernization

CORE_PRINCIPLES:
1. Preserve all business logic exactly
2. Never modify legacy code - always create new
3. Follow modern architectural patterns
4. Ensure comprehensive test coverage
5. Maintain API compatibility when required
6. Document all architectural decisions

RESPONSE_REQUIREMENTS:
- Always respond in valid JSON format
- Include complete file contents, not snippets
- Provide clear explanations for decisions
- Highlight any assumptions made
- Suggest next steps or dependencies

ERROR_HANDLING:
- If requirements are unclear, ask for clarification
- If conflicts arise, prioritize business logic preservation
- If constraints cannot be met, explain alternatives
```

### 8. **Sistema de Prompt Management**

```python
class PromptManager:
    def __init__(self, prompts_base_path: str):
        self.prompts_path = prompts_base_path
        self.prompt_cache = {}
        
    def load_prompt(self, category: str, prompt_name: str) -> str:
        """Carrega prompt especÃ­fico de arquivo"""
        prompt_path = f"{self.prompts_path}/{category}/{prompt_name}.md"
        
        if prompt_path not in self.prompt_cache:
            with open(prompt_path, 'r', encoding='utf-8') as f:
                self.prompt_cache[prompt_path] = f.read()
                
        return self.prompt_cache[prompt_path]
    
    def build_contextualized_prompt(self, 
                                   base_prompt: str, 
                                   context: dict, 
                                   variables: dict = None) -> str:
        """ConstrÃ³i prompt contextualizado com variÃ¡veis"""
        
        # Substitui variÃ¡veis no template
        if variables:
            for key, value in variables.items():
                base_prompt = base_prompt.replace(f"{{{key}}}", str(value))
        
        # Adiciona contexto especÃ­fico
        contextualized = f"""
{base_prompt}

SPECIFIC_CONTEXT:
{json.dumps(context, indent=2)}

BEGIN_ANALYSIS:
"""
        return contextualized
    
    def get_prompt_for_phase(self, phase: str, task: str) -> str:
        """Retorna prompt apropriado para fase especÃ­fica"""
        prompt_map = {
            "analysis": {
                "system": "analysis/system_analysis.md",
                "business_logic": "analysis/business_logic_extraction.md",
                "api": "analysis/api_discovery.md"
            },
            "decomposition": {
                "features": "decomposition/feature_decomposition.md",
                "backlog": "decomposition/backlog_creation.md"
            },
            "generation": {
                "code": "generation/code_generation.md",
                "tests": "generation/test_generation.md"
            },
            "validation": {
                "business": "validation/business_validation.md",
                "quality": "validation/quality_assessment.md"
            }
        }
        
        prompt_file = prompt_map.get(phase, {}).get(task)
        if not prompt_file:
            raise ValueError(f"No prompt found for phase: {phase}, task: {task}")
            
        return self.load_prompt(phase, task)
```

### 9. **Versionamento e EvoluÃ§Ã£o de Prompts**

```yaml
# EstratÃ©gia de versionamento dos prompts
prompt_versioning:
  strategy: "git-based"
  
  structure:
    - v1.0/  # VersÃ£o base
    - v1.1/  # Melhorias incrementais
    - experimental/  # Prompts em teste
    
  testing:
    - A/B testing com prompts diferentes
    - MÃ©tricas de qualidade de resposta
    - Feedback loop para melhorias
    
  documentation:
    - Changelog para cada versÃ£o
    - Exemplos de uso
    - MÃ©tricas de performance
```

```yaml
# ConfiguraÃ§Ã£o para Reengenharia de Sistema Legacy
reengineering_config:
  # Sistema Legacy
  legacy_system:
    path: "/path/to/legacy/system"
    language: "java"
    version: "8"
    framework: "struts" # ou qualquer framework antigo
    
  # Sistema Novo (Target)
  target_system:
    java_version: "17"
    framework: "spring-boot"
    version: "3.2.0"
    build_tool: "maven"
    architecture: "clean-architecture"
    patterns: ["domain-driven-design", "cqrs", "event-sourcing"]
    testing: ["junit5", "testcontainers", "mockito"]
    
  # EstratÃ©gia de Reengenharia
  reengineering_strategy:
    approach: "ground-up-rebuild"  # ground-up-rebuild | hybrid
    analysis_depth: "deep"         # surface | medium | deep
    feature_prioritization: "business-value" # complexity | dependencies | business-value
    
  # AnÃ¡lise do Sistema Legacy
  analysis_config:
    extract_business_rules: true
    map_data_flows: true
    identify_apis: true
    analyze_god_classes: true
    detect_anti_patterns: true
    
  # Knowledge Base
  knowledge_extraction:
    embedding_model: "microsoft/codebert-base"
    chunk_size: 1024
    overlap: 100
    include_comments: true
    include_tests: true
    
  # Feature Decomposition
  feature_management:
    max_feature_complexity: "medium"
    min_feature_value: "high"
    dependency_handling: "smart"  # ignore | smart | strict
    
  # Quality Standards
  quality_requirements:
    test_coverage: 90
    cyclomatic_complexity: 10
    code_duplication: 3
    maintainability_index: 85
    
  # Business Rules Preservation
  business_constraints:
    - "preserve_all_business_logic"
    - "maintain_data_integrity"
    - "ensure_api_compatibility"
    - "keep_performance_characteristics"
    
  # Exclusions from Analysis
  exclusions:
    - "*/test/*"
    - "*/target/*"
    - "*/build/*"
    - "*.class"
    - "*/lib/*"
    - "*/vendor/*"
```

### 10. **ConfiguraÃ§Ã£o do Arquivo Instr.md para Reengenharia**

#### Deep System Analysis:
```python
class DeepSystemAnalyzer:
    def analyze_legacy_system(self, system_path: str) -> SystemKnowledge:
        """AnÃ¡lise profunda multi-dimensional do sistema legacy"""
        
        # 1. AnÃ¡lise estrutural
        structure = self.analyze_code_structure(system_path)
        
        # 2. ExtraÃ§Ã£o de lÃ³gica de negÃ³cio  
        business_logic = self.extract_business_logic(structure)
        
        # 3. Mapeamento de APIs
        apis = self.discover_apis(structure)
        
        # 4. AnÃ¡lise de fluxo de dados
        data_flows = self.map_data_flows(structure)
        
        # 5. IdentificaÃ§Ã£o de god classes
        god_classes = self.identify_god_classes(structure)
        
        # 6. DetecÃ§Ã£o de anti-patterns
        anti_patterns = self.detect_anti_patterns(structure)
        
        return SystemKnowledge(
            structure=structure,
            business_logic=business_logic,
            apis=apis,
            data_flows=data_flows,
            problems=god_classes + anti_patterns
        )
```

#### Feature Decomposition Algorithm:
```python
class IntelligentFeatureDecomposer:
    def decompose_system(self, knowledge: SystemKnowledge) -> FeatureBacklog:
        """DecompÃµe sistema em features independentes"""
        
        # 1. Identificar bounded contexts
        contexts = self.identify_bounded_contexts(knowledge.business_logic)
        
        # 2. Extrair features por contexto
        raw_features = []
        for context in contexts:
            features = self.extract_features_from_context(context)
            raw_features.extend(features)
        
        # 3. Analisar dependÃªncias entre features
        dependencies = self.analyze_feature_dependencies(raw_features)
        
        # 4. Priorizar features
        prioritized = self.prioritize_features(raw_features, dependencies)
        
        # 5. Criar acceptance criteria
        backlog = []
        for feature in prioritized:
            criteria = self.generate_acceptance_criteria(feature, knowledge)
            backlog.append(FeatureTask(feature, criteria))
            
        return FeatureBacklog(backlog)
```

### 9. **Context Assembly para Reengenharia**

```python
class ReengineeringContextAssembler:
    def assemble_feature_context(self, feature: Feature, knowledge_base: KnowledgeBase) -> dict:
        """Monta contexto especÃ­fico para reengenharia de uma feature"""
        
        context = {
            "feature_specification": feature.specification,
            "business_rules": self.extract_relevant_business_rules(feature, knowledge_base),
            "legacy_implementations": self.find_legacy_implementations(feature, knowledge_base),
            "data_models": self.extract_data_models(feature, knowledge_base),
            "api_contracts": self.extract_api_contracts(feature, knowledge_base),
            "test_scenarios": self.generate_test_scenarios(feature, knowledge_base),
            "architecture_constraints": self.get_architecture_constraints(feature),
            "quality_requirements": self.get_quality_requirements(feature)
        }
        
        return self.optimize_context_for_ai(context)
        
    def build_amazon_q_prompt(self, feature: Feature, context: dict) -> str:
        """ConstrÃ³i prompt especÃ­fico para reengenharia"""
        return f"""
        TASK: Reengineer the following feature from legacy Java system to modern Spring Boot
        
        FEATURE: {feature.name}
        DESCRIPTION: {feature.description}
        
        LEGACY_CONTEXT:
        {json.dumps(context['legacy_implementations'], indent=2)}
        
        BUSINESS_RULES:
        {json.dumps(context['business_rules'], indent=2)}
        
        TARGET_ARCHITECTURE:
        - Spring Boot 3.2.0
        - Clean Architecture
        - Domain-Driven Design
        - Test-Driven Development
        
        API_CONTRACTS_TO_PRESERVE:
        {json.dumps(context['api_contracts'], indent=2)}
        
        QUALITY_REQUIREMENTS:
        - Test Coverage: 90%+
        - No God Classes
        - Single Responsibility Principle
        - Dependency Injection
        
        EXPECTED_OUTPUT: {{
            "status": "success|error",
            "files": [{{
                "path": "relative/path/to/file",
                "content": "complete_file_content",
                "purpose": "description of file purpose",
                "tests": "corresponding_test_file_content"
            }}],
            "architecture_notes": "explanation of architectural decisions",
            "business_logic_preserved": "confirmation of business rules preservation",
            "api_compatibility": "assessment of API compatibility",
            "next_dependencies": ["list of features this depends on"],
            "integration_points": ["how this integrates with other features"]
        }}
        
        IMPORTANT: Create completely new, clean code. Do not try to modify legacy code.
        """
```

### 10. **Sistema de ValidaÃ§Ã£o de Reengenharia**

```python
class ReengineeringValidator:
    def validate_reengineered_feature(self, 
                                     original_feature: LegacyFeature,
                                     new_feature: ModernFeature) -> ValidationResult:
        """Valida se a reengenharia preservou funcionalidade"""
        
        results = ValidationResult()
        
        # 1. ValidaÃ§Ã£o de lÃ³gica de negÃ³cio
        business_logic_preserved = self.validate_business_logic(
            original_feature.business_rules,
            new_feature.implementation
        )
        results.add_check("business_logic", business_logic_preserved)
        
        # 2. ValidaÃ§Ã£o de contratos de API
        api_compatibility = self.validate_api_compatibility(
            original_feature.apis,
            new_feature.apis
        )
        results.add_check("api_compatibility", api_compatibility)
        
        # 3. ValidaÃ§Ã£o de comportamento (testes funcionais)
        behavioral_compatibility = self.run_behavioral_tests(
            original_feature.test_scenarios,
            new_feature.implementation
        )
        results.add_check("behavior", behavioral_compatibility)
        
        # 4. ValidaÃ§Ã£o de qualidade de cÃ³digo
        code_quality = self.assess_code_quality(new_feature.implementation)
        results.add_check("quality", code_quality)
        
        return results
```

### 11. **Estimativas de Performance para Reengenharia**

#### MÃ©tricas Realistas:
- **Deep System Analysis**: ~2-5 horas para sistema mÃ©dio (100k LOC)
- **Feature Decomposition**: ~30-60 minutos por bounded context
- **Context Assembly**: ~30 segundos por feature
- **AI Generation per Feature**: ~1-3 minutos (dependendo da complexidade)
- **Validation per Feature**: ~2-5 minutos

#### Escalabilidade:
- **Sistema Pequeno** (10k LOC): ~1-2 dias
- **Sistema MÃ©dio** (100k LOC): ~1-2 semanas  
- **Sistema Grande** (1M LOC): ~1-2 meses

#### ParalelizaÃ§Ã£o:
- AnÃ¡lise inicial: sequencial
- Feature generation: altamente paralela
- ValidaÃ§Ã£o: paralela por feature independente

### 10. **Pontos CrÃ­ticos de ValidaÃ§Ã£o TÃ©cnica**

## EspecificaÃ§Ãµes TÃ©cnicas Detalhadas

### 1. **Interface Amazon Q CLI**

#### Comandos Principais:
```bash
# Chat interativo com JSON estruturado
q chat "<prompt>" --no-interactive --trust-all-tools -f json

# ConfiguraÃ§Ã£o de formato de saÃ­da
q settings format json-pretty

# VerificaÃ§Ã£o de status
q doctor
```

#### Estrutura de ComunicaÃ§Ã£o:
```python
class AmazonQInterface:
    def __init__(self):
        self.base_command = "q chat"
        self.flags = "--no-interactive --trust-all-tools -f json-pretty"
    
    def build_prompt(self, context: dict, task: str) -> str:
        """ConstrÃ³i prompt estruturado para garantir resposta JSON"""
        return f"""
        CONTEXT: {json.dumps(context)}
        TASK: {task}
        
        RESPONSE_FORMAT: {{
            "status": "success|error",
            "files": [{{
                "path": "relative/path/to/file",
                "content": "file_content",
                "changes": ["list of changes made"]
            }}],
            "dependencies": ["list of new dependencies"],
            "next_steps": ["suggested next actions"],
            "warnings": ["potential issues"]
        }}
        """
```

### 2. **Arquitetura RAG/GraphRAG para AnÃ¡lise de Contexto**

#### Stack TecnolÃ³gico:
- **Embeddings**: Microsoft CodeBERT (`microsoft/codebert-base`)
- **Banco de Dados**: SQLite com extensÃµes para busca vetorial
- **Graph Database**: NetworkX para anÃ¡lise de dependÃªncias
- **Vector Search**: FAISS ou ChromaDB integrado

#### Componentes do Sistema RAG:

```mermaid
graph TD
    A[ğŸ“ CÃ³digo Legacy] --> B[ğŸ” Code Parser]
    B --> C[ğŸ§  CodeBERT Embeddings]
    C --> D[ğŸ“Š SQLite + Vector Store]
    
    E[â“ Query do UsuÃ¡rio] --> F[ğŸ” Embedding Query]
    F --> G[ğŸ¯ Similarity Search]
    G --> D
    D --> H[ğŸ“‹ Context Retrieval]
    
    I[ğŸ•¸ï¸ Dependency Graph] --> J[ğŸ“ˆ GraphRAG Analysis]
    J --> H
    H --> K[ğŸ¤– Amazon Q Interface]
    
    style C fill:#e1f5fe
    style D fill:#fff3e0
    style J fill:#e8f5e8
```

#### Schema do Banco SQLite:

```sql
-- Tabela principal de arquivos
CREATE TABLE files (
    id INTEGER PRIMARY KEY,
    path TEXT UNIQUE,
    content TEXT,
    hash TEXT,
    last_modified TIMESTAMP,
    file_type TEXT,
    complexity_score REAL
);

-- Tabela de embeddings
CREATE TABLE embeddings (
    id INTEGER PRIMARY KEY,
    file_id INTEGER,
    chunk_id INTEGER,
    embedding BLOB,  -- Vector binÃ¡rio do CodeBERT
    chunk_content TEXT,
    start_line INTEGER,
    end_line INTEGER,
    FOREIGN KEY (file_id) REFERENCES files(id)
);

-- Tabela de dependÃªncias (GraphRAG)
CREATE TABLE dependencies (
    id INTEGER PRIMARY KEY,
    source_file_id INTEGER,
    target_file_id INTEGER,
    dependency_type TEXT,  -- import, inheritance, composition, etc.
    strength REAL,  -- peso da dependÃªncia
    FOREIGN KEY (source_file_id) REFERENCES files(id),
    FOREIGN KEY (target_file_id) REFERENCES files(id)
);

-- Tabela de contextos otimizados
CREATE TABLE contexts (
    id INTEGER PRIMARY KEY,
    query_hash TEXT,
    context_files TEXT,  -- JSON array de file_ids
    relevance_score REAL,
    created_at TIMESTAMP
);
```

### 3. **Algoritmo de SeleÃ§Ã£o de Contexto Inteligente**

```python
class IntelligentContextSelector:
    def __init__(self):
        self.codebert_model = "microsoft/codebert-base"
        self.max_context_tokens = 80000  # Limite do Amazon Q
        self.db = SQLiteVectorDB()
        self.graph = DependencyGraph()
    
    def select_context(self, query: str, max_files: int = 10) -> dict:
        """Algoritmo hÃ­brido RAG + GraphRAG"""
        
        # 1. Embedding Similarity Search
        query_embedding = self.encode_query(query)
        similar_chunks = self.db.similarity_search(query_embedding, top_k=20)
        
        # 2. Graph-based expansion
        relevant_files = set()
        for chunk in similar_chunks:
            file_id = chunk['file_id']
            # Adicionar dependÃªncias transitivas
            dependencies = self.graph.get_dependencies(file_id, depth=2)
            relevant_files.update([file_id] + dependencies)
        
        # 3. Ranking inteligente
        ranked_files = self.rank_files_by_relevance(
            relevant_files, query, similar_chunks
        )
        
        # 4. OtimizaÃ§Ã£o por tokens
        selected_files = self.optimize_token_usage(
            ranked_files[:max_files], self.max_context_tokens
        )
        
        return {
            "files": selected_files,
            "total_tokens": self.estimate_tokens(selected_files),
            "relevance_scores": self.get_relevance_scores(selected_files)
        }
```

### 4. **Pipeline de Processamento Incremental**

#### Estados Detalhados com MÃ©tricas:

```mermaid
stateDiagram-v2
    [*] --> Init: Inicializar Sistema
    Init --> LoadConfig: Carregar Instr.md
    LoadConfig --> BuildEmbeddings: Processar Projeto Legacy
    BuildEmbeddings --> BuildGraph: Analisar DependÃªncias
    BuildGraph --> PlanMigration: Gerar Plano de MigraÃ§Ã£o
    
    PlanMigration --> ProcessStep: PrÃ³xima Etapa
    ProcessStep --> SelectContext: RAG Context Selection
    SelectContext --> QueryAmazonQ: Consulta Estruturada
    QueryAmazonQ --> ParseResponse: Parse JSON Response
    ParseResponse --> ValidateCode: ValidaÃ§Ã£o SintÃ¡tica
    ValidateCode --> RunTests: Testes Automatizados
    
    RunTests --> Success: âœ… Sucesso
    RunTests --> Failure: âŒ Falha
    
    Success --> UpdateGraph: Atualizar DependÃªncias
    UpdateGraph --> SaveProgress: Salvar Estado
    SaveProgress --> CheckComplete: Verificar ConclusÃ£o
    
    Failure --> AnalyzeError: Analisar Erro
    AnalyzeError --> RefineContext: Refinar Contexto
    RefineContext --> SelectContext
    
    CheckComplete --> ProcessStep: Mais Etapas
    CheckComplete --> GenerateReport: Finalizar
    GenerateReport --> [*]
    
    note right of QueryAmazonQ
        q chat "<structured_prompt>" 
        --no-interactive 
        --trust-all-tools 
        -f json-pretty
    end note
    
    note right of BuildEmbeddings
        CodeBERT Embeddings
        SQLite Vector Store
        Chunking Strategy
    end note
```

### 5. **Sistema de Cache e OtimizaÃ§Ã£o**

```python
class CacheManager:
    def __init__(self):
        self.context_cache = {}  # Cache de contextos por query
        self.response_cache = {}  # Cache de respostas do Amazon Q
        self.embedding_cache = {}  # Cache de embeddings
    
    def get_cached_context(self, query_hash: str) -> Optional[dict]:
        """Recupera contexto em cache se disponÃ­vel"""
        return self.db.get_cached_context(query_hash)
    
    def cache_amazon_q_response(self, query_hash: str, response: dict):
        """Cache respostas para evitar chamadas duplicadas"""
        self.db.save_response_cache(query_hash, response)
    
    def invalidate_cache_for_file(self, file_path: str):
        """Invalida cache quando arquivo Ã© modificado"""
        self.db.invalidate_file_cache(file_path)
```

### 6. **MÃ©tricas e Monitoramento**

```python
class MetricsCollector:
    def __init__(self):
        self.metrics = {
            "queries_to_amazon_q": 0,
            "context_selection_time": [],
            "files_processed": 0,
            "successful_generations": 0,
            "failed_generations": 0,
            "cache_hit_rate": 0.0
        }
    
    def track_context_selection(self, duration: float, relevance: float):
        """Monitora eficiÃªncia da seleÃ§Ã£o de contexto"""
        self.metrics["context_selection_time"].append(duration)
    
    def generate_report(self) -> dict:
        """Gera relatÃ³rio de performance"""
        return {
            "efficiency": self.calculate_efficiency(),
            "accuracy": self.calculate_accuracy(),
            "resource_usage": self.get_resource_usage()
        }
```

## Pontos CrÃ­ticos de ValidaÃ§Ã£o

### 12. **Pontos CrÃ­ticos de ValidaÃ§Ã£o para Reengenharia**

#### AnÃ¡lise de Sistema Legacy:
- âœ… Capacidade de identificar god classes e anti-patterns
- âœ… ExtraÃ§Ã£o completa de regras de negÃ³cio
- âœ… Mapeamento de APIs e contratos existentes
- âœ… AnÃ¡lise de fluxo de dados end-to-end

#### DecomposiÃ§Ã£o Inteligente:
- âœ… IdentificaÃ§Ã£o correta de bounded contexts
- âœ… Features independentes e coesas
- âœ… PriorizaÃ§Ã£o baseada em valor e dependÃªncias
- âœ… Acceptance criteria completos e testÃ¡veis

#### GeraÃ§Ã£o de CÃ³digo Novo:
- âœ… CÃ³digo limpo seguindo princÃ­pios SOLID
- âœ… Arquitetura moderna (Clean Architecture, DDD)
- âœ… PreservaÃ§Ã£o de toda lÃ³gica de negÃ³cio
- âœ… Compatibilidade de APIs quando necessÃ¡rio

#### ValidaÃ§Ã£o de Reengenharia:
- âœ… Testes funcionais automÃ¡ticos
- âœ… VerificaÃ§Ã£o de contratos de API
- âœ… AnÃ¡lise de qualidade de cÃ³digo
- âœ… Performance equivalente ou melhor

## QuestÃµes para ValidaÃ§Ã£o da Abordagem de Reengenharia

### **EstratÃ©gia Fundamental:**
1. âœ… A mudanÃ§a de "migraÃ§Ã£o" para "reengenharia" resolve o problema das god classes?
2. âœ… A anÃ¡lise profunda captura suficientemente a lÃ³gica de negÃ³cio?
3. âœ… A decomposiÃ§Ã£o em features Ã© viÃ¡vel para sistemas complexos?
4. âœ… O approach "ground-up rebuild" Ã© mais seguro que tentar migrar cÃ³digo ruim?

### **ImplementaÃ§Ã£o TÃ©cnica:**
5. âœ… O sistema de knowledge extraction Ã© robusto o suficiente?
6. âœ… A validaÃ§Ã£o garante preservaÃ§Ã£o completa da funcionalidade?
7. âœ… O contexto para Amazon Q Ã© especÃ­fico e detalhado o suficiente?
8. âœ… As estimativas de tempo sÃ£o realistas para sistemas grandes?

### **Riscos e MitigaÃ§Ãµes:**
9. âœ… Como garantir que nenhuma regra de negÃ³cio seja perdida?
10. âœ… Como lidar com dependÃªncias entre features durante a construÃ§Ã£o?
11. âœ… Como validar que o novo sistema tem comportamento idÃªntico?
12. âœ… Como gerenciar a transiÃ§Ã£o do sistema antigo para o novo?

### **PrÃ³ximos Passos da Reengenharia:**
- ğŸ”„ Implementar analisador profundo de sistemas legacy
- ğŸ”„ Criar decomposer inteligente de features
- ğŸ”„ Desenvolver sistema de validaÃ§Ã£o comportamental
- ğŸ”„ Testar com sistema legacy real pequeno

---

**ï¿½ Aguardando validaÃ§Ã£o da nova abordagem de REENGENHARIA para proceder com implementaÃ§Ã£o!**
