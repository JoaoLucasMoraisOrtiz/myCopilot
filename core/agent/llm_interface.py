"""
Agent LLM Interface Module

ResponsÃ¡vel pela comunicaÃ§Ã£o com o LLM e gestÃ£o de contexto.
"""

from core.llm.llm_client import LLMClient


class AgentLLMInterface:
    """Classe responsÃ¡vel pela comunicaÃ§Ã£o e gestÃ£o de contexto com o LLM."""
    
    def __init__(self):
        pass
    
    def call_llm(self, messages: list, current_turn: int = 0) -> str:
        """
        Chama o LLM com gestÃ£o inteligente de contexto.
        
        Args:
            messages: Lista de mensagens da conversa
            current_turn: Turno atual para aplicar pressÃ£o temporal
            
        Returns:
            Resposta do LLM
        """
        # Limita o tamanho total do contexto para evitar overflow
        # Apenas as Ãºltimas mensagens sÃ£o enviadas para evitar duplicaÃ§Ã£o de contexto
        last_messages = messages[-4:]
        prompt = '\n'.join([f"{msg['role'].upper()}: {msg['content']}" for msg in last_messages])
        
        # Adiciona pressÃ£o temporal baseada no nÃºmero de turnos
        pressure_message = self._get_pressure_message(current_turn)
        if pressure_message:
            print(f"ğŸ¯ APLICANDO PRESSÃƒO TEMPORAL (Turno {current_turn}): {pressure_message[:80]}...")
            prompt += f"\n\nUSER: {pressure_message}"
        
        # GestÃ£o inteligente de contexto
        original_length = len(prompt)
        
        # Log do tamanho final do prompt
        print(f"ğŸ“Š Enviando prompt de {len(prompt)} chars para o LLM...")
        
        # Conecta e envia para o LLM
        client = LLMClient()
        client.connect()
        response = client.send_prompt(prompt)
        client.close()
        
        # Log da resposta recebida
        if response:
            print(f"ğŸ“¨ Resposta recebida: {len(response)} chars")
            if len(response) > 20000:
                print("âš ï¸ Resposta muito grande detectada - processamento otimizado serÃ¡ aplicado")
        
        return response
    
    def _get_pressure_message(self, current_turn: int) -> str:
        """Gera mensagens de pressÃ£o temporal baseadas no nÃºmero de turnos."""
        
        if current_turn >= 8:
            return ("URGENTE: VocÃª estÃ¡ no turno 8/10. DEVE fornecer final_answer no PRÃ“XIMO turno "
                   "ou perderÃ¡ a oportunidade de responder. Analise se jÃ¡ tem informaÃ§Ã£o suficiente "
                   "para uma resposta Ãºtil.")
        elif current_turn >= 6:
            return ("ATENÃ‡ÃƒO: VocÃª estÃ¡ no turno 6/10. Comece a considerar seriamente usar final_answer. "
                   "VocÃª tem informaÃ§Ã£o suficiente para uma resposta parcial Ãºtil?")
        elif current_turn >= 5:
            return ("REFLEXÃƒO: JÃ¡ coletou bastante informaÃ§Ã£o. Avalie se pode fornecer uma resposta Ãºtil "
                   "ou se precisa de apenas mais 1-2 observaÃ§Ãµes especÃ­ficas.")
        elif current_turn >= 4:
            return ("FOCO: VocÃª estÃ¡ na metade do caminho. Mantenha o foco no objetivo principal "
                   "e evite exploraÃ§Ãµes tangenciais.")
        else:
            return None  # Sem pressÃ£o nos primeiros turnos
