""" 
    Antes de iniciar execute em outro terminal: google-chrome --remote-debugging-port=9222 --user-data-dir=/tmp/chrome-debug --remote-allow-origins=*
"""

import os
import sys
import json
from datetime import datetime
from migration_prompts import PROMPTS
from helper.context_manager import save_md, load_context, append_to_context
from llm_client import LLMClient
from helper.code_parser import extract_code_blocks, save_code_to_file, extract_structured_code_blocks, save_structured_code_block
from helper.task_manager import TaskManager
from code_analyzer import CodeAnalyzer
from project_structure_manager import ProjectStructureManager
from migration_config_manager import MigrationConfigManager
from smart_context_manager import SmartContextManager

OUTPUT_DIR = "migration_docs"
CODE_DIR = os.path.join(OUTPUT_DIR, "generated_code")
LOGS_DIR = os.path.join(OUTPUT_DIR, "logs")
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(CODE_DIR, exist_ok=True)
os.makedirs(LOGS_DIR, exist_ok=True)

# Vari√°vel global para diret√≥rio do sistema legado
LEGACY_DIRECTORY = None

# Inicializa os gerenciadores
project_manager = ProjectStructureManager(OUTPUT_DIR)
config_manager = MigrationConfigManager(OUTPUT_DIR)
smart_context = SmartContextManager(OUTPUT_DIR, max_context_size=8000)

def log_llm_interaction(prompt_key, prompt_text, response_text, context_size=0, token_estimate=0):
    """Registra intera√ß√µes com o LLM para an√°lise e debug"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Cria log estruturado
    log_entry = {
        "timestamp": timestamp,
        "prompt_key": prompt_key,
        "context_size_chars": context_size,
        "token_estimate": token_estimate,
        "prompt_text": prompt_text,
        "response_text": response_text,
        "response_size_chars": len(response_text)
    }
    
    # Salva log JSON para an√°lise program√°tica
    json_log_file = os.path.join(LOGS_DIR, f"llm_log_{timestamp}.json")
    with open(json_log_file, 'w', encoding='utf-8') as f:
        json.dump(log_entry, f, ensure_ascii=False, indent=2)
    
    # Salva log markdown para leitura humana
    md_log_file = os.path.join(LOGS_DIR, f"llm_log_{timestamp}.md")
    log_content = f"""# Log LLM Interaction - {timestamp}

## üìã Metadados
- **Prompt Key:** {prompt_key}
- **Timestamp:** {timestamp}
- **Context Size:** {context_size:,} caracteres
- **Token Estimate:** {token_estimate:,} tokens
- **Response Size:** {len(response_text):,} caracteres

## üì§ PROMPT ENVIADO
```
{prompt_text}
```

## üì• RESPOSTA RECEBIDA
{response_text}

---
*Log gerado automaticamente pelo sistema de migra√ß√£o*
"""
    
    save_md(md_log_file, log_content)
    
    # Adiciona entrada ao log consolidado
    consolidated_log = os.path.join(LOGS_DIR, "consolidated_log.md")
    summary_entry = f"""
## {timestamp} - {prompt_key}
- **Context:** {context_size:,} chars
- **Response:** {len(response_text):,} chars
- **Files:** `llm_log_{timestamp}.json`, `llm_log_{timestamp}.md`

"""
    append_to_context(consolidated_log, summary_entry)
    
    print(f"üìù Log salvo: llm_log_{timestamp}.json/.md")
    return json_log_file, md_log_file

def run_prompt_with_llm(llm_client, prompt_key, doc_filename, context_files=None, legacy_directory=None):
    print(f"\n=== {prompt_key} ===")
    print("Enviando prompt para o LLM...")
    
    # Constr√≥i contexto completo
    full_context = build_comprehensive_context(context_files, legacy_directory)
    
    # Combina contexto com prompt
    if full_context:
        full_prompt = f"{full_context}\n\n---\n\n{PROMPTS[prompt_key]}"
    else:
        full_prompt = PROMPTS[prompt_key]
    
    # Calcula estimativa de tokens (aproximadamente 4 caracteres por token)
    context_size = len(full_context) if full_context else 0
    total_prompt_size = len(full_prompt)
    token_estimate = total_prompt_size // 4
    
    print(f"üìä Context: {context_size:,} chars | Total: {total_prompt_size:,} chars | ~{token_estimate:,} tokens")
    
    # Envia para LLM
    response = llm_client.send_prompt(full_prompt)
    
    # Registra intera√ß√£o no log
    log_llm_interaction(prompt_key, full_prompt, response, context_size, token_estimate)
    
    # Salva resposta
    save_md(os.path.join(OUTPUT_DIR, doc_filename), response)
    print(f"Resposta salva em: {doc_filename}")
    
    # Extrai c√≥digo se houver
    code_blocks = extract_code_blocks(response)
    if code_blocks:
        print(f"Encontrados {len(code_blocks)} blocos de c√≥digo")
        for i, block in enumerate(code_blocks):
            code_filename = f"{doc_filename[:-3]}_{i}.{block['language']}"
            code_path = os.path.join(CODE_DIR, code_filename)
            save_code_to_file(block['code'], code_path)
            print(f"C√≥digo salvo em: {code_filename}")
    
    return response

def build_comprehensive_context(context_files=None, legacy_directory=None):
    """Constr√≥i contexto completo incluindo Fase 0, workspace legado e contexto anterior"""
    context_parts = []
    
    # 1. CONTEXTO DA FASE 0 (Configura√ß√£o de Migra√ß√£o) - SEMPRE INCLUIR SE DISPON√çVEL
    try:
        # Verifica se h√° configura√ß√£o carregada
        if hasattr(config_manager, 'requirements') and config_manager.requirements:
            migration_context = config_manager.generate_migration_context()
            if migration_context and migration_context.strip():
                # Remove header duplicado se existir
                clean_migration = migration_context.replace("## üéØ CONFIGURA√á√ÉO DE MIGRA√á√ÉO (FASE 0)", "")
                context_parts.append(f"# CONFIGURA√á√ÉO DA MIGRA√á√ÉO (FASE 0)\n{clean_migration.strip()}")
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao carregar contexto da migra√ß√£o: {e}")
    
    # 2. CONTEXTO DO WORKSPACE LEGADO  
    if legacy_directory and os.path.exists(legacy_directory):
        legacy_context = build_legacy_workspace_context(legacy_directory)
        if legacy_context:
            context_parts.append(f"# SISTEMA LEGADO ANALISADO\n{legacy_context}")
    
    # 3. CONTEXTO ANTERIOR DAS FASES (apenas resultados principais, muito limitado)
    if context_files:
        previous_results = load_previous_results_only([os.path.join(OUTPUT_DIR, f) for f in context_files])
        if previous_results:
            # Limita drasticamente o contexto anterior j√° que temos RAG
            if len(previous_results) > 800:  # Reduz de 1500 para 800 chars
                previous_results = previous_results[:800] + "\n[...an√°lises anteriores truncadas - use RAG para detalhes]"
            context_parts.append(f"# AN√ÅLISES ANTERIORES (RESUMO M√çNIMO)\n{previous_results}")
    
    return "\n\n".join(context_parts) if context_parts else ""

def build_smart_context_for_task(task_description: str, task_type: str = "implementation") -> str:
    """Constr√≥i contexto otimizado tipo RAG para tasks espec√≠ficas"""
    print(f"üß† Construindo contexto inteligente para task ({task_type})...")
    
    # Usa o sistema de contexto inteligente
    smart_context_result = smart_context.build_smart_context_for_task(task_description, task_type)
    
    # Adiciona informa√ß√µes espec√≠ficas do sistema legado se dispon√≠vel
    if LEGACY_DIRECTORY and os.path.exists(LEGACY_DIRECTORY):
        legacy_summary = get_compact_legacy_summary(LEGACY_DIRECTORY)
        if legacy_summary:
            smart_context_result += f"\n\n# SISTEMA LEGADO (RESUMO)\n{legacy_summary}"
    
    return smart_context_result

def get_compact_legacy_summary(legacy_directory: str) -> str:
    """Obt√©m resumo super compacto do sistema legado (m√°ximo 1000 chars)"""
    try:
        # Tecnologias detectadas (mais conciso)
        technologies = detect_technologies(legacy_directory)
        tech_summary = []
        for tech, indicators in technologies.items():
            tech_summary.append(f"{tech}({len(indicators)})")
        
        summary_parts = []
        
        if tech_summary:
            summary_parts.append(f"**Tecnologias**: {', '.join(tech_summary[:5])}")
        
        # Estrutura super compacta (s√≥ diret√≥rios principais)
        main_dirs = []
        try:
            items = os.listdir(legacy_directory)
            for item in items[:10]:
                item_path = os.path.join(legacy_directory, item)
                if os.path.isdir(item_path) and not item.startswith('.'):
                    main_dirs.append(item)
        except:
            pass
        
        if main_dirs:
            summary_parts.append(f"**Estrutura**: {', '.join(main_dirs[:8])}")
        
        # Arquivos de configura√ß√£o importantes
        config_files = []
        try:
            for root, dirs, files in os.walk(legacy_directory):
                dirs[:] = [d for d in dirs if not d.startswith('.')][:3]  # Limita profundidade
                for file in files:
                    if file in ['pom.xml', 'web.xml', 'application.properties', 'package.json']:
                        rel_path = os.path.relpath(os.path.join(root, file), legacy_directory)
                        config_files.append(rel_path)
                        if len(config_files) >= 3:
                            break
                if len(config_files) >= 3:
                    break
        except:
            pass
        
        if config_files:
            summary_parts.append(f"**Configs**: {', '.join(config_files)}")
        
        return ' | '.join(summary_parts)
        
    except Exception as e:
        return f"Erro ao analisar sistema legado: {str(e)[:100]}"

def update_knowledge_base_after_phase(context_files):
    """Atualiza a base de conhecimento ap√≥s cada fase"""
    print("üìö Atualizando base de conhecimento...")
    smart_context.update_from_files(context_files)
    
    # Mostra estat√≠sticas
    stats = smart_context.get_context_stats()
    print(f"üìä KB Stats: {stats['total_documents']} docs, {stats['total_size']:,} chars")

def load_previous_results_only(file_paths):
    """Carrega apenas os resultados das fases anteriores, filtrando prompts de forma mais agressiva"""
    results = []
    
    for file_path in file_paths:
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Estrat√©gia mais agressiva para remover prompts
                lines = content.split('\n')
                filtered_lines = []
                skip_section = False
                
                for i, line in enumerate(lines):
                    line_lower = line.lower().strip()
                    
                    # Detecta in√≠cio de se√ß√µes de prompt (mais abrangente)
                    prompt_indicators = [
                        'prompt ', '**prompt', 'instru√ß√µes para', 'desenvolva',
                        'importante:** detalhe', 'organize por sprints',
                        'considere as tecnologias', 'baseado na an√°lise'
                    ]
                    
                    if any(indicator in line_lower for indicator in prompt_indicators):
                        skip_section = True
                        continue
                    
                    # Detecta fim de se√ß√£o de prompt
                    if skip_section:
                        # Se encontra nova se√ß√£o principal (# t√≠tulo), para de pular
                        if line.startswith('#') and not line.startswith('###'):
                            skip_section = False
                        # Se linha em branco seguida de texto sem indenta√ß√£o, pode ser fim de prompt
                        elif line.strip() == '' and i + 1 < len(lines):
                            next_line = lines[i + 1].strip()
                            if next_line and not next_line.startswith(' ') and not any(indicator in next_line.lower() for indicator in prompt_indicators):
                                skip_section = False
                        else:
                            continue
                    
                    # Remove linhas que claramente s√£o instru√ß√µes
                    if any(phrase in line_lower for phrase in [
                        'detalhe a execu√ß√£o', 'organize por sprints', 'deliverables claros',
                        'importante:**', 'instru√ß√µes:', 'desenvolva planos'
                    ]):
                        continue
                    
                    # Inclui linha se n√£o estiver em se√ß√£o de prompt
                    if not skip_section:
                        filtered_lines.append(line)
                
                # Remove linhas vazias consecutivas e limita tamanho
                filtered_content = '\n'.join(filtered_lines)
                
                # Remove m√∫ltiplas linhas vazias consecutivas
                import re
                filtered_content = re.sub(r'\n\s*\n\s*\n', '\n\n', filtered_content)
                
                # Limita drasticamente o tamanho do contexto anterior
                if len(filtered_content) > 1000:  # Reduz de 2000 para 1000 caracteres
                    filtered_content = filtered_content[:1000] + "\n[...resumo truncado para otimiza√ß√£o]"
                
                if filtered_content.strip():
                    filename = os.path.basename(file_path)
                    
                    # Extrai apenas as primeiras se√ß√µes importantes
                    important_sections = []
                    current_section = []
                    section_title = None
                    
                    for line in filtered_content.split('\n'):
                        if line.startswith('##') and not line.startswith('###'):
                            # Salva se√ß√£o anterior se tiver conte√∫do relevante
                            if section_title and current_section:
                                section_content = '\n'.join(current_section)
                                if len(section_content.strip()) > 50:  # S√≥ inclui se√ß√µes com conte√∫do substancial
                                    important_sections.append(f"{section_title}\n{section_content}")
                            
                            section_title = line
                            current_section = []
                        else:
                            current_section.append(line)
                    
                    # Salva √∫ltima se√ß√£o
                    if section_title and current_section:
                        section_content = '\n'.join(current_section)
                        if len(section_content.strip()) > 50:
                            important_sections.append(f"{section_title}\n{section_content}")
                    
                    # Usa apenas as 2 primeiras se√ß√µes importantes
                    if important_sections:
                        final_content = '\n\n'.join(important_sections[:2])
                        results.append(f"## {filename}\n{final_content}")
                    
            except Exception as e:
                print(f"Erro ao carregar {file_path}: {e}")
    
    return '\n\n'.join(results)

def build_legacy_workspace_context(legacy_directory):
    """Constr√≥i contexto compacto do workspace do sistema legado"""
    context_parts = []
    
    try:
        # Estrutura compacta de diret√≥rios (m√°ximo 1000 chars)
        structure = get_directory_structure(legacy_directory, max_depth=2)
        if structure:
            # Limita o tamanho da estrutura
            if len(structure) > 1000:
                lines = structure.split('\n')
                structure = '\n'.join(lines[:30]) + '\n[...truncated]'
            context_parts.append(f"## Estrutura\n```\n{structure}\n```")
        
        # Tecnologias detectadas (mais conciso)
        technologies = detect_technologies(legacy_directory)
        if technologies:
            tech_summary = []
            for tech, indicators in technologies.items():
                count = len(indicators)
                tech_summary.append(f"{tech}({count})")
            context_parts.append(f"## Tecnologias\n{', '.join(tech_summary[:8])}")  # M√°ximo 8 tecnologias
        
        # Apenas 2 amostras de c√≥digo mais relevantes
        code_samples = get_code_samples(legacy_directory)
        if code_samples:
            context_parts.append("## C√≥digo Principal")
            sample_count = 0
            for file_path, content in code_samples.items():
                if sample_count >= 2:  # Reduz de 5 para 2 amostras
                    break
                relative_path = os.path.relpath(file_path, legacy_directory)
                # Limita cada amostra a 300 caracteres
                truncated_content = content[:300] + '...' if len(content) > 300 else content
                context_parts.append(f"### {relative_path}\n```{get_file_extension(file_path)}\n{truncated_content}\n```")
                sample_count += 1
        
    except Exception as e:
        context_parts.append(f"‚ùå Erro: {str(e)[:100]}")
    
    return "\n\n".join(context_parts) if context_parts else ""

def get_directory_structure(directory, max_depth=3, current_depth=0):
    """Obt√©m estrutura de diret√≥rios de forma compacta"""
    if current_depth >= max_depth:
        return ""
    
    structure = []
    try:
        items = sorted(os.listdir(directory))
        # Filtra itens importantes e limita quantidade
        important_items = []
        other_items = []
        
        for item in items:  # aqui era limitado a 15 itens
            if item.startswith('.'):
                continue  # Pula arquivos ocultos
            item_path = os.path.join(directory, item)
            
            # Prioriza arquivos/pastas importantes
            if any(keyword in item.lower() for keyword in ['src', 'main', 'config', 'pom.xml', 'web.xml', 'service', 'controller']):
                important_items.append((item, item_path))
            else:
                other_items.append((item, item_path))
        
        # Combina priorizando importantes
        selected_items = important_items + other_items[:max(0, 15-len(important_items))]
        
        for item, item_path in selected_items:
            if os.path.isdir(item_path):
                structure.append(f"{item}/")
                if current_depth < max_depth - 1:
                    sub_structure = get_directory_structure(item_path, max_depth, current_depth + 1)
                    if sub_structure:
                        # Formato compacto: pasta/subpasta/arquivo
                        for line in sub_structure.split('\n'):
                            if line.strip():
                                structure.append(f"{item}/{line}")
            else:
                structure.append(item)
                
    except PermissionError:
        structure.append("[Access Denied]")
    
    return '\n'.join(structure)

def find_main_files(directory):
    """Encontra arquivos principais por tipo"""
    main_files = {
        "Configura√ß√£o": [],
        "Build": [],
        "C√≥digo Principal": [],
        "Testes": [],
        "Documenta√ß√£o": []
    }
    
    config_files = [
        'pom.xml', 'build.gradle', 'package.json', 'requirements.txt',
        'web.xml', 'application.properties', 'application.yml',
        'Dockerfile', 'docker-compose.yml'
    ]
    
    build_files = ['Makefile', 'build.xml', 'build.gradle', 'pom.xml']
    doc_files = ['README.md', 'README.txt', 'CHANGELOG.md', 'docs']
    
    try:
        for root, dirs, files in os.walk(directory):
            # Evita diret√≥rios de build/cache
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['target', 'build', 'node_modules', '__pycache__']]
            
            for file in files:
                file_path = os.path.join(root, file)
                file_lower = file.lower()
                
                # Arquivos de configura√ß√£o
                if file in config_files:
                    main_files["Configura√ß√£o"].append(file_path)
                # Arquivos de build
                elif file in build_files:
                    main_files["Build"].append(file_path)
                # Testes
                elif 'test' in file_lower or file.endswith(('Test.java', 'test.py', 'spec.js')):
                    main_files["Testes"].append(file_path)
                # Documenta√ß√£o
                elif file in doc_files or file.endswith(('.md', '.txt', '.doc')):
                    main_files["Documenta√ß√£o"].append(file_path)
                # C√≥digo principal
                elif file.endswith(('.java', '.py', '.js', '.ts', '.cs', '.cpp', '.c')):
                    main_files["C√≥digo Principal"].append(file_path)
    
    except Exception as e:
        print(f"Erro ao analisar arquivos: {e}")
    
    return {k: v for k, v in main_files.items() if v}

def detect_technologies(directory):
    """Detecta tecnologias baseadas em arquivos encontrados (vers√£o otimizada)"""
    technologies = {}
    file_count = 0
    max_files = 100  # Limita an√°lise a 100 arquivos
    
    try:
        for root, dirs, files in os.walk(directory):
            if file_count >= max_files:
                break
                
            # Evita diret√≥rios desnecess√°rios
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['target', 'build', 'node_modules', '__pycache__']]
            
            for file in files[:10]:  # M√°ximo 10 arquivos por diret√≥rio
                if file_count >= max_files:
                    break
                    
                file_count += 1
                
                # Detecta tecnologias principais apenas
                if file.endswith('.java'):
                    technologies.setdefault('Java', []).append(file)
                elif file == 'pom.xml':
                    technologies.setdefault('Maven', []).append(file)
                elif file == 'web.xml':
                    technologies.setdefault('JavaEE', []).append(file)
                elif file.endswith('.py'):
                    technologies.setdefault('Python', []).append(file)
                elif file == 'package.json':
                    technologies.setdefault('NodeJS', []).append(file)
                elif file.endswith(('.html', '.jsp')):
                    technologies.setdefault('Web', []).append(file)
                elif file.endswith('.sql'):
                    technologies.setdefault('SQL', []).append(file)
    
    except Exception as e:
        print(f"Erro ao detectar tecnologias: {e}")
    
    # Retorna apenas as 5 tecnologias mais encontradas
    sorted_tech = sorted(technologies.items(), key=lambda x: len(x[1]), reverse=True)
    return dict(sorted_tech[:5])

def get_code_samples(directory):
    """Obt√©m amostras compactas dos arquivos mais relevantes"""
    samples = {}
    sample_count = 0
    max_samples = 2  # Reduz de 5 para 2
    
    try:
        for root, dirs, files in os.walk(directory):
            if sample_count >= max_samples:
                break
                
            # Evita diret√≥rios desnecess√°rios
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['target', 'build', 'node_modules', '__pycache__', 'logs']]
            
            # Foca apenas em arquivos cr√≠ticos
            critical_files = [f for f in files if any(keyword in f.lower() for keyword in [
                'main', 'app', 'service', 'controller', 'config', 'web.xml', 'pom.xml', 'application'
            ])]
            
            for file in critical_files:
                if sample_count >= max_samples:
                    break
                    
                if file.endswith(('.java', '.xml', '.properties', '.yml')):
                    file_path = os.path.join(root, file)
                    try:
                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                            content = f.read()
                            if content.strip() and len(content) > 50:  # Apenas arquivos n√£o vazios e relevantes
                                samples[file_path] = content
                                sample_count += 1
                    except Exception:
                        continue
    
    except Exception as e:
        print(f"Erro ao obter amostras de c√≥digo: {e}")
    
    return samples

def get_file_extension(file_path):
    """Obt√©m extens√£o do arquivo para syntax highlighting"""
    ext = os.path.splitext(file_path)[1].lower()
    extension_map = {
        '.java': 'java',
        '.py': 'python', 
        '.js': 'javascript',
        '.ts': 'typescript',
        '.xml': 'xml',
        '.yml': 'yaml',
        '.yaml': 'yaml',
        '.properties': 'properties',
        '.sql': 'sql',
        '.html': 'html',
        '.css': 'css',
        '.json': 'json'
    }
    return extension_map.get(ext, 'text')

def fase0(llm_client=None):
    """Fase 0: Configura√ß√£o de Migra√ß√£o - Coleta requisitos do usu√°rio"""
    print("\nüöÄ FASE 0: Configura√ß√£o de Migra√ß√£o")
    print("Esta fase coleta suas prefer√™ncias para personalizar todo o processo.")
    
    choice = input("\nComo deseja fornecer os requisitos?\n[1] Interativo [2] Arquivo YAML/JSON [3] Pular (usar padr√£o): ").strip()
    
    if choice == '1':
        # Coleta interativa
        requirements = config_manager.collect_user_requirements_interactive()
    elif choice == '2':
        # Carrega de arquivo
        file_path = input("Caminho do arquivo de configura√ß√£o: ").strip()
        if os.path.exists(file_path):
            requirements = config_manager.load_requirements_from_file(file_path)
        else:
            print("‚ùå Arquivo n√£o encontrado. Usando configura√ß√£o padr√£o.")
            return None
    else:
        # Pula configura√ß√£o
        print("‚è≠Ô∏è Pulando configura√ß√£o personalizada. Usando padr√£o.")
        return None
    
    # Gera contexto inicial e salva
    migration_context = config_manager.generate_migration_context()
    
    # Inicializa contexto global com configura√ß√£o do usu√°rio
    global_context_file = os.path.join(OUTPUT_DIR, "global_context.md")
    initial_content = f"""# Contexto Global da Migra√ß√£o

**Iniciado em:** {__import__('datetime').datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

{migration_context}

## üìä Hist√≥rico de Feedback

Este arquivo cont√©m o feedback acumulado de todas as valida√ß√µes e integra√ß√µes realizadas durante o processo de migra√ß√£o.

"""
    save_md(global_context_file, initial_content)
    
    # Atualiza estrutura do projeto baseada nos requisitos
    config_manager.update_project_structure_config(project_manager)
    
    # Gera relat√≥rio de configura√ß√£o
    summary = config_manager.generate_summary_report()
    summary_file = os.path.join(OUTPUT_DIR, "migration_configuration.md")
    save_md(summary_file, summary)
    
    print("‚úÖ Configura√ß√£o conclu√≠da!")
    print(f"üìÑ Configura√ß√£o salva em: {summary_file}")
    print(f"üîß Contexto global inicializado com suas prefer√™ncias")
    
    return requirements

def fase1(llm_client):
    print("\nüèóÔ∏è  FASE 1: An√°lise do Sistema Legado")
    
    # Solicita diret√≥rio do sistema legado se n√£o foi definido
    global LEGACY_DIRECTORY
    if not LEGACY_DIRECTORY or not os.path.exists(LEGACY_DIRECTORY):
        LEGACY_DIRECTORY = input("\nüìÅ Caminho do diret√≥rio do sistema legado: ").strip()
        
        if not os.path.exists(LEGACY_DIRECTORY):
            print(f"‚ùå Diret√≥rio n√£o encontrado: {LEGACY_DIRECTORY}")
            print("üí° Dica: Use um caminho absoluto para o diret√≥rio do c√≥digo legado")
            return []
    
    print(f"‚úÖ Analisando sistema legado em: {LEGACY_DIRECTORY}")
    
    context_files = []
    
    run_prompt_with_llm(llm_client, "P1_1", "architecture-analysis.md", context_files, LEGACY_DIRECTORY)
    context_files.append("architecture-analysis.md")
    
    run_prompt_with_llm(llm_client, "P1_2", "business-flows.md", context_files, LEGACY_DIRECTORY)
    context_files.append("business-flows.md")
    
    run_prompt_with_llm(llm_client, "P1_3", "dependencies-analysis.md", context_files, LEGACY_DIRECTORY)
    context_files.append("dependencies-analysis.md")
    
    # Atualiza base de conhecimento ap√≥s Fase 1
    update_knowledge_base_after_phase(context_files)
    
    return context_files

def fase2(llm_client, context_files):
    print("\nüó∫Ô∏è  FASE 2: Constru√ß√£o do Roadmap")
    
    run_prompt_with_llm(llm_client, "P2_1", "technical-glossary.md", context_files, LEGACY_DIRECTORY)
    context_files.append("technical-glossary.md")
    
    run_prompt_with_llm(llm_client, "P2_2", "component-roadmap.md", context_files, LEGACY_DIRECTORY)
    context_files.append("component-roadmap.md")
    
    run_prompt_with_llm(llm_client, "P2_3", "risk-analysis.md", context_files, LEGACY_DIRECTORY)
    context_files.append("risk-analysis.md")
    
    # Atualiza base de conhecimento ap√≥s Fase 2
    update_knowledge_base_after_phase(context_files)
    
    return context_files

def fase3(llm_client, context_files):
    print("\nüìã FASE 3: Cria√ß√£o de Tasks")
    
    run_prompt_with_llm(llm_client, "P3_1", "target-architecture.md", context_files, LEGACY_DIRECTORY)
    context_files.append("target-architecture.md")
    
    # Configura estrutura do projeto baseada na arquitetura alvo
    target_arch_file = os.path.join(OUTPUT_DIR, "target-architecture.md")
    if os.path.exists(target_arch_file):
        with open(target_arch_file, 'r', encoding='utf-8') as f:
            target_architecture_content = f.read()
        
        print("üèóÔ∏è Configurando estrutura do novo sistema...")
        project_manager.update_structure_from_target_architecture(target_architecture_content)
        print("‚úÖ Estrutura do projeto configurada")
        print(project_manager.get_structure_overview())
    
    run_prompt_with_llm(llm_client, "P3_2", "migration-backlog.md", context_files, LEGACY_DIRECTORY)
    context_files.append("migration-backlog.md")
    
    run_prompt_with_llm(llm_client, "P3_3", "testing-strategy.md", context_files, LEGACY_DIRECTORY)
    context_files.append("testing-strategy.md")
    
    # Atualiza base de conhecimento ap√≥s Fase 3
    update_knowledge_base_after_phase(context_files)
    
    return context_files

def fase4(llm_client, context_files):
    print("\n‚ö° FASE 4: Itera√ß√£o e Implementa√ß√£o")
    
    # Inicializa contexto global se necess√°rio
    initialize_global_context()
    
    task_manager = TaskManager(OUTPUT_DIR)
    
    while True:
        task_index, task = task_manager.get_next_task()
        if not task:
            print("‚úÖ Todas as tasks foram conclu√≠das!")
            break
        
        print(f"\nüìù Pr√≥xima Task: {task['title']}")
        print(f"Descri√ß√£o: {task['description'][:100]}...")
        
        choice = input("\n[1] Implementar [2] Pular [3] Sair: ").strip()
        
        if choice == '1':
            # Carrega contexto melhorado (incluindo feedback global)
            enhanced_context = load_enhanced_context(context_files)
            implement_task(llm_client, task, enhanced_context, task_index, task_manager)
        elif choice == '2':
            continue
        elif choice == '3':
            break
        else:
            print("Op√ß√£o inv√°lida")

def implement_task(llm_client, task, context, task_index, task_manager):
    # P4.1: Implementa√ß√£o com contexto inteligente
    project_structure = project_manager.get_structure_overview()
    
    # *** NOVA IMPLEMENTA√á√ÉO: Usa contexto inteligente em vez do contexto tradicional ***
    print("üß† Construindo contexto otimizado para implementa√ß√£o...")
    smart_context_result = build_smart_context_for_task(task['description'], "implementation")
    
    implementation_prompt = PROMPTS["P4_1"].format(
        task_description=task['description'],
        project_structure=project_structure
    )
    
    # Usa o contexto inteligente em vez do contexto original
    full_prompt = f"CONTEXTO OTIMIZADO:\n{smart_context_result}\n\n{implementation_prompt}"
    
    # Calcula m√©tricas do prompt otimizado
    context_size = len(smart_context_result)
    total_prompt_size = len(full_prompt)
    token_estimate = total_prompt_size // 4
    
    print(f"üî® Implementando...")
    print(f"üìä Context Otimizado: {context_size:,} chars | Total: {total_prompt_size:,} chars | ~{token_estimate:,} tokens")
    
    # Compara com contexto original para mostrar economia
    original_context_size = len(context) if context else 0
    if original_context_size > 0:
        reduction_pct = ((original_context_size - context_size) / original_context_size) * 100
        print(f"üí° Redu√ß√£o de contexto: {reduction_pct:.1f}% ({original_context_size:,} ‚Üí {context_size:,} chars)")
    
    code_response = llm_client.send_prompt(full_prompt)
    
    # Registra intera√ß√£o da implementa√ß√£o
    log_llm_interaction(f"P4_1_Task_{task_index}", full_prompt, code_response, context_size, token_estimate)
    
    # Salva c√≥digo
    impl_file = f"task_{task_index}_implementation.md"
    save_md(os.path.join(OUTPUT_DIR, impl_file), code_response)
    
    # Tenta extrair blocos estruturados primeiro
    structured_blocks = extract_structured_code_blocks(code_response)
    saved_files = []
    
    if structured_blocks:
        print(f"üìÅ Encontrados {len(structured_blocks)} blocos de c√≥digo estruturados")
        for i, block in enumerate(structured_blocks):
            try:
                file_path = project_manager.save_generated_file(
                    code_content=block.code,
                    code_language=block.language,
                    task_index=task_index,
                    task_description=block.description,
                    component_hint=block.component
                )
                saved_files.append(file_path)
                print(f"üìÑ {block.filename} ‚Üí {file_path}")
            except Exception as e:
                print(f"‚ùå Erro ao salvar {block.filename}: {e}")
    else:
        # Fallback para extra√ß√£o tradicional
        print("‚ö†Ô∏è Formato estruturado n√£o encontrado, usando extra√ß√£o tradicional...")
        code_blocks = extract_code_blocks(code_response)
        for i, block in enumerate(code_blocks):
            file_path = project_manager.save_generated_file(
                code_content=block['code'],
                code_language=block['language'],
                task_index=task_index,
                task_description=task['description'],
                component_hint=""
            )
            saved_files.append(file_path)
    
    if saved_files:
        print(f"‚úÖ Arquivos gerados e organizados: {len(saved_files)}")
        for file_path in saved_files:
            print(f"   üìÑ {file_path}")
        
        # Gera resumo do projeto atualizado
        summary = project_manager.generate_project_summary()
        summary_file = os.path.join(OUTPUT_DIR, "project_summary.md")
        save_md(summary_file, summary)
        
        # P4.2: Valida√ß√£o (otimizada)
        print("üîç Validando com contexto otimizado...")
        
        # Constr√≥i contexto espec√≠fico para valida√ß√£o (mais compacto)
        validation_context = build_smart_context_for_task(task['description'], "validation")
        
        # Combina o prompt de valida√ß√£o com contexto otimizado
        base_validation_prompt = PROMPTS["P4_2"].format(code_to_validate=code_response)
        validation_prompt_with_context = f"CONTEXTO PARA VALIDA√á√ÉO:\n{validation_context[:2000]}\n\n{base_validation_prompt}"
        
        validation = llm_client.send_prompt(validation_prompt_with_context)
        
        # Registra intera√ß√£o da valida√ß√£o
        log_llm_interaction(f"P4_2_Task_{task_index}", validation_prompt_with_context, validation, 
                          len(validation_context[:2000]), len(validation_prompt_with_context) // 4)
        
        validation_file = f"task_{task_index}_validation.md"
        save_md(os.path.join(OUTPUT_DIR, validation_file), validation)
        
        if "‚úÖ APROVADO" in validation:
            # ‚úÖ P4_2 -.-> Context3: Atualiza contexto global com valida√ß√£o bem-sucedida
            update_global_context_with_validation(task_index, task['title'], validation, is_approved=True)
            
            # P4.3: Integra√ß√£o (otimizada)
            print("üîó Planejando integra√ß√£o com contexto otimizado...")
            
            # Constr√≥i contexto espec√≠fico para integra√ß√£o (mais compacto)
            integration_context = build_smart_context_for_task(task['description'], "integration")
            
            # Combina o prompt de integra√ß√£o com contexto otimizado
            base_integration_prompt = PROMPTS["P4_3"].format(implemented_code=code_response)
            integration_prompt_with_context = f"CONTEXTO PARA INTEGRA√á√ÉO:\n{integration_context[:2000]}\n\n{base_integration_prompt}"
            
            integration = llm_client.send_prompt(integration_prompt_with_context)
            
            # Registra intera√ß√£o da integra√ß√£o
            log_llm_interaction(f"P4_3_Task_{task_index}", integration_prompt_with_context, integration, 
                              len(integration_context[:2000]), len(integration_prompt_with_context) // 4)
            
            integration_file = f"task_{task_index}_integration.md"
            save_md(os.path.join(OUTPUT_DIR, integration_file), integration)
            
            # ‚úÖ P4_3 -.-> Context3: Atualiza contexto global com plano de integra√ß√£o
            update_global_context_with_integration(task_index, task['title'], integration, success=True)
            
            task_manager.mark_task_completed(task_index)
            print("‚úÖ Task conclu√≠da com sucesso!")
        else:
            # ‚ùå P4_2 -.-> Context3: Atualiza contexto global com valida√ß√£o rejeitada
            update_global_context_with_validation(task_index, task['title'], validation, is_approved=False)
            
            print("‚ùå C√≥digo rejeitado na valida√ß√£o.")
            print("üîÑ Iniciando ciclo de refinamento...")
            
            # Ciclo de refinamento (mant√©m a l√≥gica existente)
            max_attempts = 3
            attempt = 1
            
            while attempt <= max_attempts:
                print(f"\nüî® Tentativa de refinamento {attempt}/{max_attempts}")
                
                # Extrai motivo da falha da valida√ß√£o
                failure_reason = extract_failure_reason(validation)
                
                # Prompt de refinamento
                refinement_prompt = f"""
REFINAMENTO DE C√ìDIGO - Tentativa {attempt}

C√ìDIGO ORIGINAL QUE FALHOU:
{code_response}

MOTIVO DA FALHA NA VALIDA√á√ÉO:
{failure_reason}

VALIDA√á√ÉO COMPLETA:
{validation}

ESTRUTURA DO PROJETO:
{project_structure}

INSTRU√á√ïES PARA REFINAMENTO:
1. Analise cuidadosamente o motivo da falha
2. Corrija os problemas identificados
3. Mantenha a funcionalidade original intacta
4. Melhore a qualidade do c√≥digo conforme sugerido
5. Use o FORMATO ESTRUTURADO para a resposta
6. Forne√ßa uma explica√ß√£o das corre√ß√µes feitas

Por favor, gere uma vers√£o corrigida do c√≥digo que atenda aos crit√©rios de valida√ß√£o.
"""
                
                print("üî® Refinando c√≥digo...")
                refined_response = llm_client.send_prompt(refinement_prompt)
                
                # Registra intera√ß√£o do refinamento
                log_llm_interaction(f"P4_1_Refinement_{attempt}_Task_{task_index}", refinement_prompt, refined_response, 0, len(refinement_prompt) // 4)
                
                # Salva a tentativa de refinamento
                refinement_file = f"task_{task_index}_refinement_{attempt}.md"
                save_md(os.path.join(OUTPUT_DIR, refinement_file), refined_response)
                
                # Processa c√≥digo refinado
                refined_structured_blocks = extract_structured_code_blocks(refined_response)
                if refined_structured_blocks:
                    for block in refined_structured_blocks:
                        try:
                            file_path = project_manager.save_generated_file(
                                code_content=block.code,
                                code_language=block.language,
                                task_index=task_index,
                                task_description=f"REFINEMENT_{attempt}_{block.description}",
                                component_hint=block.component
                            )
                            print(f"üîÑ Refinado: {block.filename} ‚Üí {file_path}")
                        except Exception as e:
                            print(f"‚ùå Erro ao salvar refinamento: {e}")
                    
                    # Valida c√≥digo refinado (otimizado)
                    print("üîç Validando c√≥digo refinado com contexto otimizado...")
                    
                    # Usa contexto otimizado para valida√ß√£o do refinamento
                    refined_validation_context = build_smart_context_for_task(task['description'], "validation")
                    base_refined_validation_prompt = PROMPTS["P4_2"].format(code_to_validate=refined_response)
                    refined_validation_prompt = f"CONTEXTO PARA VALIDA√á√ÉO:\n{refined_validation_context[:1500]}\n\n{base_refined_validation_prompt}"
                    
                    refined_validation = llm_client.send_prompt(refined_validation_prompt)
                    
                    # Registra intera√ß√£o da valida√ß√£o refinada
                    log_llm_interaction(f"P4_2_Refinement_{attempt}_Task_{task_index}", refined_validation_prompt, 
                                      refined_validation, len(refined_validation_context[:1500]), len(refined_validation_prompt) // 4)
                    
                    refined_validation_file = f"task_{task_index}_validation_refined_{attempt}.md"
                    save_md(os.path.join(OUTPUT_DIR, refined_validation_file), refined_validation)
                    
                    if "‚úÖ APROVADO" in refined_validation:
                        # C√≥digo aprovado ap√≥s refinamento
                        print(f"‚úÖ C√≥digo aprovado na tentativa {attempt}!")
                        
                        # ‚úÖ P4_2 -.-> Context3: Atualiza contexto com valida√ß√£o refinada bem-sucedida
                        refinement_context = f"C√≥digo aprovado ap√≥s {attempt} tentativa(s) de refinamento"
                        update_global_context_with_validation(task_index, task['title'], f"{refinement_context}\n\n{refined_validation}", is_approved=True)
                        
                        # P4.3: Integra√ß√£o (otimizada p√≥s-refinamento)
                        print("üîó Planejando integra√ß√£o p√≥s-refinamento com contexto otimizado...")
                        
                        # Usa contexto otimizado para integra√ß√£o do refinamento
                        refined_integration_context = build_smart_context_for_task(task['description'], "integration")
                        base_integration_prompt = PROMPTS["P4_3"].format(implemented_code=refined_response)
                        integration_prompt = f"CONTEXTO PARA INTEGRA√á√ÉO:\n{refined_integration_context[:1500]}\n\n{base_integration_prompt}"
                        
                        integration = llm_client.send_prompt(integration_prompt)
                        
                        # Registra intera√ß√£o da integra√ß√£o p√≥s-refinamento
                        log_llm_interaction(f"P4_3_Refinement_{attempt}_Task_{task_index}", integration_prompt, 
                                          integration, len(refined_integration_context[:1500]), len(integration_prompt) // 4)
                        
                        integration_file = f"task_{task_index}_integration.md"
                        save_md(os.path.join(OUTPUT_DIR, integration_file), integration)
                        
                        # ‚úÖ P4_3 -.-> Context3: Atualiza contexto global com integra√ß√£o p√≥s-refinamento
                        refinement_integration_context = f"Integra√ß√£o planejada ap√≥s {attempt} refinamento(s)"
                        update_global_context_with_integration(task_index, task['title'], f"{refinement_integration_context}\n\n{integration}", success=True)
                        
                        task_manager.mark_task_completed(task_index)
                        print("‚úÖ Task conclu√≠da com sucesso ap√≥s refinamento!")
                        return
                    else:
                        print(f"‚ùå C√≥digo ainda rejeitado na tentativa {attempt}")
                        # ‚ùå P4_2 -.-> Context3: Atualiza contexto com valida√ß√£o refinada rejeitada
                        if attempt == max_attempts:
                            failed_refinement_context = f"C√≥digo rejeitado ap√≥s {max_attempts} tentativas de refinamento"
                            update_global_context_with_validation(task_index, task['title'], f"{failed_refinement_context}\n\n{refined_validation}", is_approved=False)
                        
                        validation = refined_validation  # Usa a nova valida√ß√£o para a pr√≥xima itera√ß√£o
                        code_response = refined_response  # Usa o c√≥digo refinado para a pr√≥xima itera√ß√£o
                        attempt += 1
                else:
                    print(f"‚ö†Ô∏è Nenhum c√≥digo estruturado gerado na tentativa {attempt}")
                    attempt += 1
            
            print(f"‚ùå Falha ap√≥s {max_attempts} tentativas de refinamento.")
            print("üìù Verifique os arquivos de valida√ß√£o para entender os problemas.")
            
            # ‚ùå P4_2 -.-> Context3: Atualiza contexto global com falha completa
            failure_context = f"Task falhou ap√≥s {max_attempts} tentativas de refinamento. Necess√°ria an√°lise manual."
            update_global_context_with_validation(task_index, task['title'], failure_context, is_approved=False)
    else:
        print("‚ö†Ô∏è Nenhum c√≥digo foi gerado.")

def initialize_global_context():
    """Inicializa o arquivo de contexto global se n√£o existir"""
    global_context_file = os.path.join(OUTPUT_DIR, "global_context.md")
    if not os.path.exists(global_context_file):
        timestamp = __import__('datetime').datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        initial_content = f"""# Contexto Global da Migra√ß√£o

**Iniciado em:** {timestamp}

Este arquivo cont√©m o feedback acumulado de todas as valida√ß√µes e integra√ß√µes realizadas durante o processo de migra√ß√£o. Ele √© automaticamente atualizado conforme o fluxograma Mermaid:

- **P4_2 -.-> Context3**: Feedback de valida√ß√µes
- **P4_3 -.-> Context3**: Feedback de integra√ß√µes

## üìä Hist√≥rico de Feedback

"""
        save_md(global_context_file, initial_content)
        print(f"üîß Contexto global inicializado em: global_context.md")

def update_global_context_with_validation(task_index, task_title, validation_result, is_approved):
    """Atualiza o contexto global com resultados de valida√ß√£o (P4_2 -.-> Context3)"""
    timestamp = __import__('datetime').datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    context_update = f"""

## üîç Feedback de Valida√ß√£o - Task {task_index} ({timestamp})
**Task:** {task_title}
**Status:** {"‚úÖ APROVADO" if is_approved else "‚ùå REJEITADO"}

### Resultado da Valida√ß√£o:
{validation_result}

### Li√ß√µes Aprendidas:
"""
    
    if is_approved:
        context_update += """- C√≥digo atendeu aos crit√©rios de qualidade
- Padr√µes arquiteturais foram seguidos corretamente
- Integra√ß√£o deve funcionar conforme esperado
"""
    else:
        failure_reason = extract_failure_reason(validation_result)
        context_update += f"""- Problemas identificados: {failure_reason}
- Necess√°rio refinamento antes da integra√ß√£o
- Revisar padr√µes de qualidade para futuras implementa√ß√µes
"""
    
    context_update += "\n---\n"
    
    # Salva no arquivo de contexto global
    global_context_file = os.path.join(OUTPUT_DIR, "global_context.md")
    append_to_context(global_context_file, context_update)
    print(f"üìù Contexto global atualizado com feedback de valida√ß√£o")

def update_global_context_with_integration(task_index, task_title, integration_plan, success=True):
    """Atualiza o contexto global com resultados de integra√ß√£o (P4_3 -.-> Context3)"""
    timestamp = __import__('datetime').datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    context_update = f"""

## üîó Feedback de Integra√ß√£o - Task {task_index} ({timestamp})
**Task:** {task_title}
**Status:** {"‚úÖ INTEGRA√á√ÉO PLANEJADA" if success else "‚ùå PROBLEMAS DE INTEGRA√á√ÉO"}

### Plano de Integra√ß√£o:
{integration_plan}

### Impacto no Sistema:
"""
    
    if success:
        context_update += """- Nova funcionalidade pronta para deploy
- Depend√™ncias mapeadas e resolvidas
- Testes de integra√ß√£o definidos
- Estrat√©gia de rollback estabelecida
"""
    else:
        context_update += """- Problemas de integra√ß√£o identificados
- Necess√°rio revisar depend√™ncias
- Poss√≠vel impacto em outras funcionalidades
- Requer an√°lise adicional antes do deploy
"""
    
    context_update += "\n---\n"
    
    # Salva no arquivo de contexto global
    global_context_file = os.path.join(OUTPUT_DIR, "global_context.md")
    append_to_context(global_context_file, context_update)
    print(f"üìù Contexto global atualizado com feedback de integra√ß√£o")

def load_enhanced_context(context_files):
    """Carrega contexto incluindo feedback global acumulado e configura√ß√£o do usu√°rio"""
    # Carrega contexto original das fases
    base_context = load_context([os.path.join(OUTPUT_DIR, f) for f in context_files])
    
    # Adiciona configura√ß√£o do usu√°rio (Fase 0)
    requirements = config_manager.load_requirements()
    if requirements:
        migration_context = config_manager.generate_migration_context()
        base_context = f"{migration_context}\n\n{base_context}"
    
    # Adiciona contexto global se existir
    global_context_file = os.path.join(OUTPUT_DIR, "global_context.md")
    if os.path.exists(global_context_file):
        global_context = load_context([global_context_file])
        return f"{base_context}\n\n## CONTEXTO GLOBAL ACUMULADO\n{global_context}"
    
    return base_context

def extract_failure_reason(validation_text):
    """Extrai o motivo principal da falha da valida√ß√£o."""
    lines = validation_text.split('\n')
    reasons = []
    
    for line in lines:
        line = line.strip()
        if any(keyword in line.lower() for keyword in ['erro', 'problema', 'falha', 'incorreto', 'inv√°lido', 'rejeitado']):
            reasons.append(line)
    
    if reasons:
        return '\n'.join(reasons[:5])  # Retorna no m√°ximo 5 motivos principais
    else:
        return "Motivo da falha n√£o claramente identificado na valida√ß√£o."

def analyze_project_code(llm_client):
    print("\nüîç AN√ÅLISE DE C√ìDIGO DO PROJETO")
    
    project_dir = input("Digite o caminho do projeto para analisar: ").strip()
    if not os.path.exists(project_dir):
        print("‚ùå Diret√≥rio n√£o encontrado.")
        return
    
    try:
        analyzer = CodeAnalyzer(project_dir, OUTPUT_DIR)
        
        # Descobre arquivos
        files = analyzer.discover_files()
        print(f"üìÅ Encontrados {len(files)} arquivos de c√≥digo")
        
        if not files:
            print("‚ö†Ô∏è Nenhum arquivo de c√≥digo encontrado no projeto.")
            return
        
        # Analisa depend√™ncias
        analyzer.analyze_dependencies(files)
        print(f"üìä Ordem de an√°lise determinada: {len(analyzer.analysis_order)} arquivos")
        
        # Analisa cada arquivo na ordem correta
        for i, file_path in enumerate(analyzer.analysis_order, 1):
            print(f"\n[{i}/{len(analyzer.analysis_order)}] Analisando...")
            try:
                analyzer.analyze_file_with_llm(llm_client, file_path)
            except Exception as e:
                print(f"‚ùå Erro ao analisar {file_path}: {e}")
                continue
        
        # Salva knowledge base
        analyzer.save_knowledge_base()
        analyzer.generate_summary_report()
        
        print("\n‚úÖ An√°lise de c√≥digo conclu√≠da!")
        print(f"üìÑ Verifique os arquivos em {OUTPUT_DIR}/")
        
    except ImportError as e:
        print(f"‚ùå Erro ao importar analisadores: {e}")
        print("Certifique-se de que os arquivos dos analisadores foram criados:")
        print("- analyzers/__init__.py")
        print("- analyzers/java_analyzer.py") 
        print("- analyzers/python_analyzer.py")
    except Exception as e:
        print(f"‚ùå Erro durante an√°lise: {e}")

def generate_logs_report():
    """Gera relat√≥rio de an√°lise dos logs de intera√ß√£o com LLM"""
    print("\nüìä AN√ÅLISE DOS LOGS LLM")
    
    if not os.path.exists(LOGS_DIR):
        print("‚ùå Nenhum log encontrado.")
        return
    
    # Lista arquivos de log JSON
    log_files = [f for f in os.listdir(LOGS_DIR) if f.startswith('llm_log_') and f.endswith('.json')]
    
    if not log_files:
        print("‚ùå Nenhum log JSON encontrado.")
        return
    
    print(f"üìÇ Analisando {len(log_files)} logs...")
    
    # Coleta estat√≠sticas
    total_interactions = 0
    total_tokens = 0
    total_context_chars = 0
    total_response_chars = 0
    prompt_types = {}
    
    logs_data = []
    
    for log_file in sorted(log_files):
        log_path = os.path.join(LOGS_DIR, log_file)
        try:
            with open(log_path, 'r', encoding='utf-8') as f:
                log_data = json.load(f)
                logs_data.append(log_data)
                
                total_interactions += 1
                total_tokens += log_data.get('token_estimate', 0)
                total_context_chars += log_data.get('context_size_chars', 0)
                total_response_chars += log_data.get('response_size_chars', 0)
                
                prompt_key = log_data.get('prompt_key', 'unknown')
                prompt_types[prompt_key] = prompt_types.get(prompt_key, 0) + 1
                
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao ler {log_file}: {e}")
    
    # Gera relat√≥rio
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_content = f"""# Relat√≥rio de An√°lise dos Logs LLM

**Gerado em:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## üìä Estat√≠sticas Gerais

- **Total de Intera√ß√µes:** {total_interactions:,}
- **Total de Tokens Estimados:** {total_tokens:,}
- **Total de Caracteres de Contexto:** {total_context_chars:,}
- **Total de Caracteres de Resposta:** {total_response_chars:,}
- **M√©dia de Tokens por Intera√ß√£o:** {total_tokens // max(total_interactions, 1):,}
- **M√©dia de Contexto por Intera√ß√£o:** {total_context_chars // max(total_interactions, 1):,} chars

## üéØ Distribui√ß√£o por Tipo de Prompt

"""
    
    for prompt_type, count in sorted(prompt_types.items()):
        percentage = (count / total_interactions) * 100
        report_content += f"- **{prompt_type}:** {count} ({percentage:.1f}%)\n"
    
    report_content += f"""

## üìà Timeline de Intera√ß√µes

| Timestamp | Prompt Type | Context | Tokens | Response |
|-----------|------------|---------|--------|----------|
"""
    
    for log_data in logs_data[-20:]:  # √öltimas 20 intera√ß√µes
        timestamp = log_data.get('timestamp', 'N/A')
        prompt_key = log_data.get('prompt_key', 'N/A')
        context_size = log_data.get('context_size_chars', 0)
        tokens = log_data.get('token_estimate', 0)
        response_size = log_data.get('response_size_chars', 0)
        
        report_content += f"| {timestamp} | {prompt_key} | {context_size:,} | {tokens:,} | {response_size:,} |\n"
    
    report_content += f"""

## üîç An√°lise de Efici√™ncia

### Contexto vs Resposta
- **Ratio Contexto/Resposta:** {(total_context_chars / max(total_response_chars, 1)):.2f}
- **Efici√™ncia de Token:** {(total_response_chars / max(total_tokens, 1)):.2f} chars/token

### Recomenda√ß√µes
"""
    
    if total_context_chars / max(total_interactions, 1) > 5000:
        report_content += "- ‚ö†Ô∏è Contexto m√©dio muito alto (>5k chars) - considerar otimiza√ß√£o\n"
    else:
        report_content += "- ‚úÖ Contexto m√©dio dentro do esperado\n"
    
    if total_tokens / max(total_interactions, 1) > 2000:
        report_content += "- ‚ö†Ô∏è Tokens m√©dios altos (>2k) - considerar redu√ß√£o de contexto\n"
    else:
        report_content += "- ‚úÖ Uso de tokens eficiente\n"
    
    # Salva relat√≥rio
    report_file = os.path.join(LOGS_DIR, f"logs_analysis_report_{timestamp}.md")
    save_md(report_file, report_content)
    
    print("‚úÖ Relat√≥rio de an√°lise gerado!")
    print(f"üìÑ Arquivo: {report_file}")
    print(f"üìä {total_interactions} intera√ß√µes analisadas")
    print(f"üéØ {total_tokens:,} tokens estimados")
    
    return report_file

def cleanup_old_logs(keep_days=30):
    """Remove logs mais antigos que X dias para economizar espa√ßo"""
    if not os.path.exists(LOGS_DIR):
        return
    
    from datetime import datetime, timedelta
    cutoff_date = datetime.now() - timedelta(days=keep_days)
    
    removed_count = 0
    total_count = 0
    
    for filename in os.listdir(LOGS_DIR):
        if filename.startswith('llm_log_') and ('.' in filename):
            total_count += 1
            try:
                # Extrai timestamp do nome do arquivo
                timestamp_str = filename.split('_')[2].split('.')[0]  # YYYYMMDD_HHMMSS
                file_date = datetime.strptime(timestamp_str, '%H%M%S')
                
                # Para compara√ß√£o, usa apenas a data atual como base
                file_date = file_date.replace(year=datetime.now().year, 
                                             month=datetime.now().month, 
                                             day=datetime.now().day)
                
                if file_date < cutoff_date:
                    file_path = os.path.join(LOGS_DIR, filename)
                    os.remove(file_path)
                    removed_count += 1
                    
            except (ValueError, IndexError):
                # Ignora arquivos com formato de nome inv√°lido
                continue
    
    if removed_count > 0:
        print(f"üßπ Limpeza de logs: {removed_count}/{total_count} arquivos removidos")
    else:
        print(f"‚úÖ Logs atualizados: {total_count} arquivos mantidos")

def show_logs_menu():
    """Menu espec√≠fico para gerenciamento de logs"""
    while True:
        print("\nüìä GERENCIAMENTO DE LOGS LLM")
        print("[1] Gerar relat√≥rio de an√°lise")
        print("[2] Listar logs dispon√≠veis")
        print("[3] Limpar logs antigos (>30 dias)")
        print("[4] Ver log consolidado")
        print("[0] Voltar ao menu principal")
        
        choice = input("Op√ß√£o: ").strip()
        
        if choice == '1':
            generate_logs_report()
        elif choice == '2':
            list_available_logs()
        elif choice == '3':
            cleanup_old_logs()
        elif choice == '4':
            show_consolidated_log()
        elif choice == '0':
            break
        else:
            print("Op√ß√£o inv√°lida")

def list_available_logs():
    """Lista todos os logs dispon√≠veis com informa√ß√µes b√°sicas"""
    if not os.path.exists(LOGS_DIR):
        print("‚ùå Nenhum log encontrado.")
        return
    
    log_files = [f for f in os.listdir(LOGS_DIR) if f.startswith('llm_log_') and f.endswith('.json')]
    
    if not log_files:
        print("‚ùå Nenhum log JSON encontrado.")
        return
    
    print(f"\nüìÇ {len(log_files)} logs dispon√≠veis:")
    print("=" * 80)
    print(f"{'Timestamp':<20} {'Prompt Key':<25} {'Tokens':<10} {'Context':<10}")
    print("=" * 80)
    
    for log_file in sorted(log_files, reverse=True):  # Mais recentes primeiro
        log_path = os.path.join(LOGS_DIR, log_file)
        try:
            with open(log_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                timestamp = data.get('timestamp', 'N/A')
                prompt_key = data.get('prompt_key', 'N/A')[:24]  # Trunca se muito longo
                tokens = data.get('token_estimate', 0)
                context = data.get('context_size_chars', 0)
                
                print(f"{timestamp:<20} {prompt_key:<25} {tokens:<10} {context:<10}")
                
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao ler {log_file}: {e}")

def show_consolidated_log():
    """Mostra o log consolidado"""
    consolidated_file = os.path.join(LOGS_DIR, "consolidated_log.md")
    if os.path.exists(consolidated_file):
        print("\nüìã LOG CONSOLIDADO:")
        print("=" * 60)
        with open(consolidated_file, 'r', encoding='utf-8') as f:
            content = f.read()
            # Mostra apenas as √∫ltimas 20 linhas para n√£o sobrecarregar
            lines = content.split('\n')
            for line in lines[-20:]:
                print(line)
    else:
        print("‚ùå Log consolidado n√£o encontrado.")

def clean_existing_files_from_prompts():
    """Remove prompts dos arquivos j√° existentes para limpeza retroativa"""
    print("\nüßπ LIMPEZA DE PROMPTS EM ARQUIVOS EXISTENTES")
    
    # Lista arquivos .md no diret√≥rio de sa√≠da
    md_files = [f for f in os.listdir(OUTPUT_DIR) if f.endswith('.md') and not f.startswith('logs')]
    
    if not md_files:
        print("‚ùå Nenhum arquivo .md encontrado para limpeza.")
        return
    
    print(f"üìÅ Encontrados {len(md_files)} arquivos para an√°lise...")
    
    cleaned_count = 0
    
    for filename in md_files:
        file_path = os.path.join(OUTPUT_DIR, filename)
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_size = len(content)
            
            # Aplica a mesma l√≥gica de limpeza da fun√ß√£o load_previous_results_only
            lines = content.split('\n')
            filtered_lines = []
            skip_section = False
            
            for i, line in enumerate(lines):
                line_lower = line.lower().strip()
                
                # Detecta se√ß√µes de prompt
                prompt_indicators = [
                    'prompt ', '**prompt', 'instru√ß√µes para', 'desenvolva',
                    'importante:** detalhe', 'organize por sprints',
                    'considere as tecnologias', 'baseado na an√°lise'
                ]
                
                if any(indicator in line_lower for indicator in prompt_indicators):
                    skip_section = True
                    continue
                
                # Detecta fim de se√ß√£o de prompt
                if skip_section:
                    if line.startswith('#') and not line.startswith('###'):
                        skip_section = False
                    elif line.strip() == '' and i + 1 < len(lines):
                        next_line = lines[i + 1].strip()
                        if next_line and not next_line.startswith(' ') and not any(indicator in next_line.lower() for indicator in prompt_indicators):
                            skip_section = False
                    else:
                        continue
                
                # Remove linhas que s√£o claramente instru√ß√µes
                if any(phrase in line_lower for phrase in [
                    'detalhe a execu√ß√£o', 'organize por sprints', 'deliverables claros',
                    'importante:**', 'instru√ß√µes:', 'desenvolva planos'
                ]):
                    continue
                
                if not skip_section:
                    filtered_lines.append(line)
            
            # Remove m√∫ltiplas linhas vazias
            import re
            filtered_content = '\n'.join(filtered_lines)
            filtered_content = re.sub(r'\n\s*\n\s*\n', '\n\n', filtered_content)
            
            new_size = len(filtered_content)
            
            # S√≥ salva se houve mudan√ßa significativa
            if new_size < original_size * 0.9:  # Se reduziu mais de 10%
                # Faz backup do original
                backup_path = file_path + '.backup'
                with open(backup_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                # Salva vers√£o limpa
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(filtered_content)
                
                reduction_pct = ((original_size - new_size) / original_size) * 100
                print(f"‚úÖ {filename}: {original_size:,} ‚Üí {new_size:,} chars ({reduction_pct:.1f}% redu√ß√£o)")
                cleaned_count += 1
            else:
                print(f"‚ö™ {filename}: J√° limpo ou sem prompts detectados")
                
        except Exception as e:
            print(f"‚ùå Erro ao processar {filename}: {e}")
    
    if cleaned_count > 0:
        print(f"\nüéâ Limpeza conclu√≠da: {cleaned_count} arquivos otimizados")
        print("üíæ Backups salvos com extens√£o .backup")
    else:
        print("\n‚úÖ Nenhum arquivo precisou de limpeza")

def main():
    print("üöÄ MIGRADOR DE SISTEMAS LEGADOS")
    print("Certifique-se de que o VS Code Web est√° aberto com o Copilot Chat ativo.")
    
    # Conecta com LLM
    try:
        llm_client = LLMClient()
        llm_client.connect()
        print("‚úÖ Conectado ao LLM")
    except Exception as e:
        print(f"‚ùå Erro ao conectar: {e}")
        return
    
    try:
        print("\nEscolha a opera√ß√£o:")
        print("[0] Fase 0: Configura√ß√£o da Migra√ß√£o (Coletamento de Requisitos)")
        print("[1] Executar todas as fases de migra√ß√£o")
        print("[2] Fase 1: An√°lise do Sistema Legado")
        print("[3] Fase 2: Constru√ß√£o do Roadmap")
        print("[4] Fase 3: Cria√ß√£o de Tasks")
        print("[5] Fase 4: Implementa√ß√£o")
        print("[6] Analisar c√≥digo de projeto existente")
        print("[7] Gerenciar logs LLM (relat√≥rios, limpeza, an√°lise)")
        print("[8] üßπ Limpar prompts de arquivos existentes")
        
        choice = input("Op√ß√£o: ").strip()
        
        if choice == '0':
            fase0()
        elif choice == '1':
            fase0()  # Sempre come√ßa com Fase 0
            context_files = fase1(llm_client)
            context_files = fase2(llm_client, context_files)
            context_files = fase3(llm_client, context_files)
            fase4(llm_client, context_files)
        elif choice == '2':
            fase1(llm_client)
        elif choice == '3':
            context_files = [f for f in os.listdir(OUTPUT_DIR) if f.endswith('.md')]
            fase2(llm_client, context_files)
        elif choice == '4':
            context_files = [f for f in os.listdir(OUTPUT_DIR) if f.endswith('.md')]
            fase3(llm_client, context_files)
        elif choice == '5':
            context_files = [f for f in os.listdir(OUTPUT_DIR) if f.endswith('.md')]
            fase4(llm_client, context_files)
        elif choice == '6':
            analyze_project_code(llm_client)
        elif choice == '7':
            show_logs_menu()
        elif choice == '8':
            clean_existing_files_from_prompts()
        else:
            print("Op√ß√£o inv√°lida")
            
        print(f"\n‚úÖ Processo conclu√≠do! Verifique os arquivos em {OUTPUT_DIR}/")
        
    finally:
        llm_client.close()

if __name__ == "__main__":
    main()
